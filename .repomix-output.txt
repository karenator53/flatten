This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-02-13T21:07:16.671Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
AI-DOC/
pages/api/
.cursorrules
.gitignore
AI-DOC/.gitattributes
cursor_log.md
docs/architecture.md
frontend/.gitignore
frontend/eslint.config.js
frontend/index.html
frontend/package.json
frontend/public/vite.svg
frontend/README.md
frontend/src/App.css
frontend/src/App.tsx
frontend/src/assets/react.svg
frontend/src/components/CodeAnalyzer.tsx
frontend/src/components/Documentation.tsx
frontend/src/components/MermaidDiagram.tsx
frontend/src/components/Navbar.tsx
frontend/src/components/RelationshipVisualizer.tsx
frontend/src/index.css
frontend/src/main.tsx
frontend/src/theme.ts
frontend/src/types/mermaid-react.d.ts
frontend/src/vite-env.d.ts
frontend/tsconfig.app.json
frontend/tsconfig.json
frontend/tsconfig.node.json
frontend/vite.config.ts
jest.config.js
LICENSE
package.json
README.md
src/api.ts
src/codeAnalyzer/index.ts
src/codeAnalyzer/languageParsers/babelParser.ts
src/codeAnalyzer/languageParsers/ILanguageParser.ts
src/codeAnalyzer/languageParsers/ParserRegistry.ts
src/codeAnalyzer/languageParsers/tsParser.ts
src/codeAnalyzer/languageParsers/yamlParser.ts
src/codeAnalyzer/projectAnalyzer.ts
src/codeAnalyzer/types.ts
src/config/config.ts
src/docGenerator.ts
src/docGenerator/helpers.ts
src/docGenerator/index.ts
src/docGenerator/templateEngine.ts
src/index.ts
src/mcp/integration.ts
src/mcp/openaiClient.ts
src/mcpHandler.ts
src/types/react-syntax-highlighter.d.ts
src/types/vfile-modules.d.ts
src/utils/fileUtils.ts
src/utils/logger.ts
start-app.bat
stop-app.bat
tests/codeAnalyzer.test.ts
tests/docGenerator.test.ts
tests/integration.assist.test.ts
tests/mcpHandler.test.ts
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".cursorrules">
<cursor-tools Integration>
# Instructions
Use the following commands to get AI assistance:

**Web Search:**
`cursor-tools web "<your question>"` - Get answers from the web using Perplexity AI (e.g., `cursor-tools web "latest weather in London"`)
when using web for complex queries suggest writing the output to a file somewhere like local-research/<query summary>.md.

**Repository Context:**
`cursor-tools repo "<your question>"` - Get context-aware answers about this repository using Google Gemini (e.g., `cursor-tools repo "explain authentication flow"`)

**Documentation Generation:**
`cursor-tools doc [options]` - Generate comprehensive documentation for this repository (e.g., `cursor-tools doc --output docs.md`)
when using doc for remote repos suggest writing the output to a file somewhere like local-docs/<repo-name>.md.

**GitHub Information:**
`cursor-tools github pr [number]` - Get the last 10 PRs, or a specific PR by number (e.g., `cursor-tools github pr 123`)
`cursor-tools github issue [number]` - Get the last 10 issues, or a specific issue by number (e.g., `cursor-tools github issue 456`)

**Browser Automation (Stateless):**
`cursor-tools browser open <url> [options]` - Open a URL and capture page content, console logs, and network activity (e.g., `cursor-tools browser open "https://example.com" --html`)
`cursor-tools browser act "<instruction>" --url=<url> [options]` - Execute actions on a webpage using natural language instructions (e.g., `cursor-tools browser act "Click Login" --url=https://example.com`)
`cursor-tools browser observe "<instruction>" --url=<url> [options]` - Observe interactive elements on a webpage and suggest possible actions (e.g., `cursor-tools browser observe "interactive elements" --url=https://example.com`)
`cursor-tools browser extract "<instruction>" --url=<url> [options]` - Extract data from a webpage based on natural language instructions (e.g., `cursor-tools browser extract "product names" --url=https://example.com/products`)

**Notes on Browser Commands:**
- All browser commands are stateless: each command starts with a fresh browser instance and closes it when done.
- When using `--connect-to`, special URL values are supported:
  - `current`: Use the existing page without reloading
  - `reload-current`: Use the existing page and refresh it (useful in development)
- Multi step workflows involving state or combining multiple actions are supported in the `act` command using the pipe (|) separator (e.g., `cursor-tools browser act "Click Login | Type 'user@example.com' into email | Click Submit" --url=https://example.com`)
- Video recording is available for all browser commands using the `--video=<directory>` option. This will save a video of the entire browser interaction at 1280x720 resolution. The video file will be saved in the specified directory with a timestamp.
- DO NOT ask browser act to "wait" for anything, the wait command is currently disabled in Stagehand.

**Tool Recommendations:**
- `cursor-tools web` is best for general web information not specific to the repository.
- `cursor-tools repo` is ideal for repository-specific questions, planning, code review and debugging.
- `cursor-tools doc` generates documentation for local or remote repositories.
- `cursor-tools browser` is useful for testing and debugging web apps.

**Running Commands:**
1. **Installed version:** Use `cursor-tools <command>` (if in PATH) or `npm exec cursor-tools "<command>"`, `yarn cursor-tools "<command>"`, `pnpm cursor-tools "<command>"`.
2. **Without installation:** Use `npx -y cursor-tools@latest "<command>"` or `bunx -y cursor-tools@latest "<command>"`.

**General Command Options (Supported by all commands):**
--model=<model name>: Specify an alternative AI model to use
--max-tokens=<number>: Control response length
--save-to=<file path>: Save command output to a file (in *addition* to displaying it)
--help: View all available options (help is not fully implemented yet)

**Documentation Command Options:**
--from-github=<GitHub username>/<repository name>[@<branch>]: Generate documentation for a remote GitHub repository

**GitHub Command Options:**
--from-github=<GitHub username>/<repository name>[@<branch>]: Access PRs/issues from a specific GitHub repository

**Browser Command Options (for 'open', 'act', 'observe', 'extract'):**
--console: Capture browser console logs (enabled by default, use --no-console to disable)
--html: Capture page HTML content
--network: Capture network activity (enabled by default, use --no-network to disable)
--screenshot=<file path>: Save a screenshot of the page
--timeout=<milliseconds>: Set navigation timeout (default: 30000ms)
--viewport=<width>x<height>: Set viewport size (e.g., 1280x720). When using --connect-to, viewport is only changed if this option is explicitly provided
--headless: Run browser in headless mode (default: true)
--no-headless: Show browser UI (non-headless mode) for debugging
--connect-to=<port>: Connect to existing Chrome instance
--wait=<duration or selector>: Wait after page load (e.g., '5s', '#element-id', 'selector:.my-class')
--video=<directory>: Save a video recording of the browser interaction to the specified directory (1280x720 resolution). Not available when using --connect-to

**Additional Notes:**
- For detailed information, see `node_modules/cursor-tools/README.md` (if installed locally).
- Configuration is in `cursor-tools.config.json` (or `~/.cursor-tools/config.json`).
- API keys are loaded from `.cursor-tools.env` (or `~/.cursor-tools/.env`).
- Browser commands require separate installation of Playwright: `npm install --save-dev playwright` or `npm install -g playwright`.
- **Remember:** You're part of a team of superhuman expert AIs. Work together to solve complex problems.
<!-- cursor-tools-version: 0.5.0 -->
</cursor-tools Integration>
</file>

<file path=".gitignore">
# flattened_repo.txt
# repo_structure.yaml
node_modules
.env
</file>

<file path="AI-DOC/.gitattributes">
# Auto detect text files and perform LF normalization
* text=auto
</file>

<file path="cursor_log.md">
# Cursor Log
  ```
  ai-code-doc-generator/
  ├── package.json
  ├── tsconfig.json
  ├── .env                  // Environment variables
  ├── README.md
  ├── jest.config.js        // Jest configuration file
  ├── LICENSE               // Project license
  ├── cursor_log.md         // Updated progress log
  ├── docs/
  │   └── architecture.md   // Architecture and design decisions
  ├── src/
  │   ├── index.ts          // MCP server entry point
  │   ├── mcpHandler.ts     // Command router for MCP messages
  │   ├── codeAnalyzer/     // Folder for code analysis modules
  │   │   ├── index.ts      // Entry point to analysis modules
  │   │   ├── types.ts      // Shared interfaces for code analysis (functions, classes, etc.)
  │   │   ├── projectAnalyzer.ts  // Newly added: project analysis function to handle project scans
  │   │   └── languageParsers/
  │   │       ├── tsParser.ts   // TypeScript analysis (using ts-morph or similar)
  │   │       └── jsParser.ts   // JavaScript analysis (using Esprima or Acorn)
  │   ├── docGenerator/
  │   │   ├── index.ts      // Documentation generation entry point
  │   │   ├── templateEngine.ts // Handlebars (or alternative) integration
  │   │   └── helpers.ts    // Custom Handlebars helpers, if needed
  │   └── utils/
  │       ├── logger.ts     // Logging and debugging utilities
  │       └── fileUtils.ts  // File system helpers for reading/writing templates, etc.
  ├── templates/
  │   ├── default.hbs       // Default documentation template
  │   └── custom.hbs        // Example custom template for further customization
  ├── node_modules/         // Project dependencies
  ├── demoProject/          // Newly added: Demo project for testing analysis
  │   └── sample.ts         // Sample TypeScript file for real data testing
  └── demoTest.ts           // Newly added: Test runner for project analysis

  ----
  Progress Updates:
  - [x] Created demoProject/sample.ts with example TypeScript code.
  - [x] Implemented analyzeProject function in src/codeAnalyzer/projectAnalyzer.ts.
  - [x] Updated ts-morph analysis in src/codeAnalyzer/index.ts to extract additional details including complete function bodies and JSDoc/comments for functions and classes.
  - [x] Added demoTest.ts to run and test the analyzeProject function on the demoProject folder.
  - [x] Extended MCP handler to support the "assist" command.
  - [x] Created integration layer in src/mcp/integration.ts that aggregates context and simulates a LangChain API call.
  - [x] Updated integration layer to use a human-friendly summarization prompt for LLM integration.
  - [x] Created an OpenAI client in src/mcp/openaiClient.ts that integrates with GPT-4o (chatgpt-4o-latest) using advanced prompts.
  - [x] Updated OpenAI client prompt to instruct the LLM to split large contexts (over 75% of 128,000 tokens) into chunks and stitch summaries together.
  - [x] Created src/api.ts with REST API endpoint /api/analyze for triggering code analysis and documentation generation.
  - [ ] Integration Plan for Universal Assistant GUI:
      - Plan to develop a web-based interface using React or Vue.js.
      - Implement folder selection, analysis trigger, and a report viewer for interactive diagnostics.
      - Create a new REST API endpoint (/api/analyze) to trigger backend code analysis and documentation generation.
      - Enhance Handlebars templates to clearly separate code blocks and descriptive sections.
      - Integrate front-end components with existing backend modules including code analysis, documentation generation, and MCP integration.
      - Add real-time progress indicators and feedback mechanisms.
      - Write unit and integration tests for the new GUI components.
  - [~] Scheduled subsequent tasks for integrating Handlebars templating enhancements and real-time progress indicators. (Tasks planned but not started yet.)
  - [~] Initiated exploration of UI framework options (React vs Vue.js) to determine the optimal approach for our GUI.
  - [~] Started designing minimal API routing in the backend to support the /api/analyze endpoint with proper request validation and error handling.
  - [x] Created initial React UI stub in src/frontend/App.tsx for folder selection, analysis trigger, and report viewer.
  - [x] Created frontend entry point in src/frontend/index.tsx which renders the App component to the DOM.
  - [x] Created public/index.html as the HTML entry point for the React app.
  - [x] Installed react, react-dom and their type declarations to support the frontend.
  - [~] Referenced design inspiration from [open-webui](https://github.com/open-webui/open-webui) for building a user-friendly interface.
  - [ ] Upcoming: Develop initial UI component stubs for folder selection, analysis trigger, and report viewer; update documentation in /docs.
  - [2023-10-30 21:55] Updated folder selection input in src/frontend/App.tsx to allow folder selection by adding non-standard attributes (webkitdirectory, directory) with a TS ignore comment.
  - [2023-10-30 22:15] DEBUG: Updated analyzeProject in src/codeAnalyzer/projectAnalyzer.ts to resolve the folder path to an absolute path using path.resolve and added logging. This should fix the ENOENT error when scanning the 'audio-visualizer' folder via the API call.
  - [2023-11-30] Updated SyntaxHighlighter components in App.tsx to replace escaped newline characters ("\n") with actual newline characters for proper formatting of both Code Analysis and OpenAI Analysis outputs.

## Temporary Development Changes (2024-01-XX)
- [x] Temporarily hardcoded AI Analysis output in App.tsx for development purposes
- Original code (to restore API functionality):
```typescript
const runAnalysis = async () => {
  setLoading(true);
  try {
    const response = await fetch('http://localhost:3000/api/analyze', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ folder })
    });
    const data = await response.json();
    setCodeOutput(data.codeOutput || '');
    setOpenaiOutput(data.openaiOutput || '');
  } catch (error) {
    setCodeOutput('Error running analysis');
    setOpenaiOutput('Error running analysis');
  } finally {
    setLoading(false);
  }
};
```

## [2024-02-12] Path Resolution Fixes
- [x] Updated path resolution logic in projectAnalyzer.ts to better handle absolute paths
- [x] Removed hardcoded path for 'audio-visualizer' in favor of more flexible path handling
- [x] Added path extraction regex to handle Windows paths with forward/backward slashes
- [x] Implemented path normalization to clean up path inconsistencies
- [x] Enhanced logging for better debugging of path resolution steps
- [x] Updated folder selection in CodeAnalyzer.tsx to properly extract folder paths
- [x] Added path cleanup to remove file references (like index.html) from selected paths
- [x] Fixed path extraction to always use absolute paths from drive root (e.g., C:\)
- [x] Simplified folder selection to use native file system dialog
- [x] Removed all path processing to use raw folder paths
- [x] Fixed directory path extraction to use actual selected folder path
- [ ] TODO: Test path resolution with various input formats
- [ ] TODO: Add error handling for malformed paths
- [ ] TODO: Consider adding path validation for security

Next Steps:
1. Test folder selection with the simplified approach
2. Add validation for secure path handling
3. Improve error messages for path-related issues
4. Add documentation for supported path formats

## Project Idea: AI-Powered Code Documentation Generator
Objective: Develop an MCP server that interfaces with Cursor to automatically generate comprehensive documentation for your codebase. This tool will analyze your code, extract relevant information, and produce well-structured documentation, thereby improving code maintainability and readability.

Key Features:
- Code Analysis: Parse the codebase to identify functions, classes, modules, and their relationships.
- Documentation Generation: Generate detailed documentation including descriptions, parameter explanations, and usage examples based on code analysis.
- Integration with Cursor: Seamlessly integrate with Cursor, allowing developers to access and update documentation directly within the IDE.

## Initialization
Below is an extended, detailed implementation outline that not only covers all the steps for building your AI-Powered Code Documentation Generator but also provides guidance on best practices, modularity, testing, and future enhancements. This outline is designed so you can easily map each step into Cursor as an MCP server project while keeping the architecture flexible and scalable.

---

## 1. Project Setup & Environment Configuration

- [x] Set up Node.js project with TypeScript.
- [x] Created repository structure and initial files.

## 2. Modular Architecture & Implementation Details

### A. MCP Server & Communication

- **MCP Entry Point (`src/index.ts`):**
  - Set up your MCP server to read incoming messages (using stdio or SSE).
  - Route messages to the MCP handler.
  - Implement robust error handling and logging.

- **MCP Handler (`src/mcpHandler.ts`):**
  - Parse incoming JSON messages conforming to the MCP protocol.
  - Switch between commands (e.g., `analyzeCode`, `generateDocs`, and future commands like `updateTemplate`).
  - Return structured responses that Cursor can interpret.

*Best Practice:* Ensure each command is validated against a schema (using libraries like Joi or Yup) to prevent malformed requests. This approach is recommended in many MCP integrations for better error handling citeturn0search0.

### B. Code Analysis Module

- **Language-Specific Parsers:**
  - Abstract the parser functionality behind a common interface.
  - For each supported language, implement a module (e.g., `tsParser.ts` for TypeScript, `jsParser.ts` for JavaScript).
  - Consider using powerful libraries like [ts-morph](https://github.com/dsherret/ts-morph) for TypeScript or tree-sitter for multi-language support.

- **Central Analysis Module (`src/codeAnalyzer/index.ts`):**
  - Dynamically select the parser based on file extension or user configuration.
  - Aggregate analysis results (functions, classes, relationships).
  - Support for additional metadata extraction (e.g., comments, annotations).

*Best Practice:* Design this as a plugin architecture where new language parsers can be added without modifying the core logic. This modularity is key for scalability and maintainability citeturn0search0.

### C. Documentation Generation Module

- **Template Engine Integration:**
  - Integrate Handlebars (or your preferred templating engine) in a dedicated module.
  - Allow loading different templates based on configuration.
  - Develop helper functions to transform analysis data into a presentable format.

- **Documentation Renderer (`src/docGenerator/index.ts`):**
  - Accept analysis data from the Code Analyzer.
  - Render documentation by injecting the data into your templates.
  - Provide options for output formats (Markdown, HTML, etc.).

*Best Practice:* Structure your templates to be modular (partials for functions, classes, etc.) so that you can easily update documentation formats without affecting core logic citeturn0search0.

### D. Configuration & Customization

- **Configuration Management:**
  - Use a configuration file (e.g., `config.json` or `.env`) to store settings such as:
    - Supported languages
    - Default template paths
    - MCP communication settings (transport method, command)
  - Create a configuration module that loads and validates these settings at startup.

- **Extensibility:**
  - Provide an API or command within the MCP server to update configurations dynamically.
  - Allow users to supply custom templates or override analysis rules via the configuration.

### E. Utilities & Helpers

- **Logging Utility:**
  - Enhance your logger to include different log levels (info, warn, error) and potentially integrate with remote logging services.
  - Ensure that logging does not leak sensitive data.

- **File System Helpers:**
  - Write functions to handle file read/write operations for templates, analysis reports, and cached results.

---

## 3. Integration with Cursor

- **Cursor Settings:**
  - In Cursor, navigate to **Settings > Features > MCP**.
  - Add your MCP server by specifying:
    - **Transport Method:** Choose `stdio` (as used in the scaffold) or SSE if you upgrade.
    - **Command:** For example, `npx ts-node ./src/index.ts` (or compile to JS and run `node ./dist/index.js`).

- **User Experience Enhancements:**
  - Provide a command palette entry in Cursor to trigger analysis or generate documentation.
  - Include error messages and logs that are visible within the Cursor IDE for easier debugging.

*Best Practice:* Regularly test the integration in a real development environment and gather feedback from users to refine the user experience. Cursor's documentation on adding MCP servers is a great reference for these details citeturn0search0.

---

## 4. Testing, CI/CD, and Iteration

- **Unit & Integration Testing:**
  - Write unit tests for each module (MCP handler, code analyzer, doc generator) using Jest or Mocha.
  - Develop integration tests that simulate MCP messages and verify end-to-end functionality.
  - Consider a small client script to mimic Cursor's MCP requests for local testing.

- **Continuous Integration/Deployment:**
  - Set up a CI/CD pipeline to automatically run tests and build your project on commits.
  - Deploy the MCP server in a staging environment first, then update your Cursor configuration for production use.

- **Feedback Loop:**
  - Iterate on features based on user feedback.
  - Monitor performance and error logs.
  - Regularly update documentation (both code and user-facing) to reflect new features or changes.

---

## 5. Future Enhancements & Considerations

- **Multi-Language Support:**  
  - Expand the language parsers to support more languages using a plugin system.
  - Add configuration to let users choose which languages to analyze.

- **Dynamic Template Updates:**
  - Allow hot-reloading or dynamic switching of templates within Cursor without restarting the MCP server.

- **Advanced Analysis Features:**
  - Include additional metadata like code complexity, dependency graphs, and inline comments extraction.
  - Integrate AI or ML models to improve natural language descriptions or generate summaries of code functionality.

- **User Interface Enhancements in Cursor:**
  - Consider adding UI elements (if supported by Cursor) to let users select analysis options, view documentation previews, or customize templates on the fly.

- **Security & Performance:**
  - Validate all input to avoid potential code injection issues.
  - Optimize the analysis process to handle large codebases efficiently (caching results, incremental analysis).

---

## Final Thoughts

This comprehensive outline should help you refine your implementation beyond steps 1 to 3, ensuring that every aspect—from modularity and configuration to testing and future enhancements—is covered. Integrating these components into Cursor via the MCP protocol will provide a robust, scalable tool for automated code documentation generation. Each module is designed to be independent, so you can replace or upgrade parts (such as the template engine or language parsers) as your project evolves.

For further details on best practices and integration tips, reviewing the official documentation for both the Model Context Protocol and Cursor's MCP server guide can be very beneficial citeturn0search0.

This outline should serve as a robust roadmap to complete your project and guide its evolution into a production-quality tool.

## Comprehensive Assessment & Recommendations
- [x] Verified repository structure against repo_structure.yaml. Confirmed presence of:
     - Top-level configuration files: cursor_log.md, jest.config.js, LICENSE, README.md, package.json.
     - /dist folder with proper subdirectories (/codeAnalyzer, /docGenerator, /utils, etc.).
     - /docs folder containing architecture documentation.
     - /node_modules and additional supporting files.

## Real Data Testing
- [ ] Create a demo project folder "demoProject" with a sample TypeScript file (demoProject/sample.ts) containing real code.
- [ ] Run the `analyzeProject` function from `src/codeAnalyzer/projectAnalyzer.ts` on "demoProject" to verify data extraction.

## Universal Assistant MCP Integration

**Project Summary:**
Evolve the code documentation project into a universal assistant using the Model Context Protocol (MCP) for unified command routing. MCP will:
- Standardize interactions across tools (code analyzer via ts-morph, documentation generator, and external APIs like OpenAI via LangChain).
- Enable extensibility & modularity for future integrations (e.g., bug trackers, CI/CD systems).
- Provide richer context to LLMs by aggregating outputs from multiple modules.

**Key Modules:**
- **`src/codeAnalyzer/`**: Houses functions like `analyzeCode` and `analyzeProject`.
- **`src/docGenerator/`**: Generates documentation (to be enhanced beyond dummy output).
- **`src/mcpHandler.ts`**: Routes MCP commands (current commands: analyzeCode, analyzeProject, generateDocs; new command to add: `assist`).
- **Proposed:** **`src/mcp/integration.ts`**: New integration layer that:
   - Aggregates context from internal modules.
   - Interfaces with LangChain (using our OpenAI API key) to generate human-friendly summaries.
- **`src/utils/logger.ts`**: Provides logging support.

**Implementation Tasks:**
- **Extend MCP Handler:**
  - Update `src/mcpHandler.ts` to support a new `assist` command with proper Joi schema validation.
  - Route the `assist` command to the integration layer.

- **Develop Integration Layer:**
  - Create `src/mcp/integration.ts` to aggregate analysis and documentation results.
  - Integrate with LangChain to process the aggregated context and return a standardized MCP response.

- **LangChain & API Integration:**
  - Configure LangChain with our OpenAI API key.
  - Define a flow: aggregate context → send query to LangChain → process the response → return MCP output.

- **Testing & Documentation:**
  - Write unit/integration tests for the new MCP commands and integration layer.
  - Update project documentation with architectural diagrams and integration instructions.
  - Integrate these tests into our CI/CD pipeline.

**References:**
- [Building a Universal Assistant to Connect with Any API](https://medium.com/heurislabs/building-a-universal-assistant-to-connect-with-any-api-89d7c353e524)
- [Model Context Protocol Documentation](https://modelcontextprotocol.io/introduction)

This section provides a clear roadmap for implementing MCP integration in a scalable, maintainable way.

References:
- [Raygun MCP Server](https://raygun.com/blog/announcing-mcp/)
- [Medium: Why Anthropic's MCP is a ground-breaking release](https://medium.com/@tuantruong_6651/why-anthropics-model-control-protocol-mcp-is-a-ground-breaking-release-a-dummy-explanation-696de7afc8b7)

# Project Progress Log

## 2024-02-12

### Major Cleanup and Frontend Setup
- Cleaned up project structure by removing unnecessary directories and files
- Simplified package.json configuration
- Set up new frontend with Vite + React + TypeScript
  - Created frontend directory with modern tooling
  - Installed all required dependencies
  - Set up routing with react-router-dom
  - Created main components (Navbar, CodeAnalyzer, Documentation)
  - Integrated with Chakra UI for styling
  - Connected to backend API for code analysis

### Current Sprint: Frontend Development
- [x] Initialize Vite + React + TypeScript project
- [x] Set up frontend routing
- [x] Create main layout components
- [x] Integrate with backend API
- [x] Implement code documentation viewer

### Next Steps
1. Add error boundaries for better error handling
2. Implement real-time analysis progress updates
3. Add more documentation features (search, filtering)
4. Add tests for frontend components
5. Add proper loading states and animations

## [2024-02-13] Frontend Development - Static Data Implementation
- [x] Added static test data for development
  - Created mock code analysis data with proper formatting
  - Created mock OpenAI analysis response
  - Added TypeScript interfaces for better type safety
  - Structured code analysis data to be more human-readable
- [ ] TODO: Add visual improvements
  - Improve code block formatting
  - Add syntax highlighting for inline code
  - Add collapsible sections for long code blocks
  - Add search/filter functionality
- [ ] TODO: Add toggle between static and dynamic data
  - Add environment variable for data source
  - Add debug mode toggle in UI
  - Add loading states and error handling

Next Steps:
1. Implement visual improvements
2. Add more test cases to static data
3. Add toggle mechanism for data source
4. Improve markdown rendering
5. Add code folding functionality

## [2024-02-13] Side-by-Side Documentation View Implementation
### Phase Overview
Implementing a new side-by-side view for code and AI analysis with structured JSON output and enhanced UI components.

### Approved Changes
- [x] Added static test data for development
- [x] Created TypeScript interfaces for structured analysis
- [x] Implemented basic side-by-side layout

### Current Sprint: Side-by-Side View Implementation
#### Phase 1: Structured OpenAI Output
- [ ] Update OpenAI prompt to request JSON output
- [ ] Add JSON schema validation using Ajv
- [ ] Implement robust error handling for JSON parsing
- [ ] Add token counting for better output splitting
- [ ] Ensure code block integrity during splitting

#### Phase 2: Frontend UI Components
- [ ] Create new component files:
  - [ ] CodeAnalysisPanel
  - [ ] AIAnalysisPanel
  - [ ] ComponentCard
- [ ] Add loading states and error boundaries
- [ ] Implement collapsible sections using Chakra UI
- [ ] Add responsive design for different screen sizes

#### Phase 3: Integration & Testing
- [ ] Create test suite for OpenAI output parsing
- [ ] Add UI component tests
- [ ] Test edge cases (missing data, partial matches)
- [ ] Add integration tests for the complete flow

### Senior Dev Feedback Implementation
1. **JSON Parsing & Validation**
   - Add try/catch blocks for JSON parsing
   - Implement Ajv schema validation
   - Handle malformed JSON gracefully

2. **Token Management**
   - Integrate token counting function
   - Add logic to prevent splitting code blocks
   - Implement smart chunk management

3. **UX Improvements**
   - Add collapsible sections
   - Implement clear loading states
   - Add error handling UI components
   - Ensure responsive design

4. **Testing Strategy**
   - Create comprehensive test suite
   - Add edge case coverage
   - Implement UI component tests
   - Add integration tests

Next Steps:
1. Begin implementation of Phase 1 (Structured OpenAI Output)
2. Set up testing infrastructure
3. Create base UI components
4. Implement error handling and validation

Dependencies to Add:
- ajv (JSON schema validation)
- @testing-library/react (UI testing)
- jest (test runner)
- gpt-tokenizer (token counting)

## [2024-02-13] Language Parser Implementation
- [x] Implemented TypeScript parser using ts-morph
  - Added support for function declarations and arrow functions
  - Added support for class definitions with methods and properties
  - Added JSDoc documentation extraction
  - Added source location tracking
- [x] Implemented JavaScript parser using ts-morph
  - Added support for function declarations, arrow functions, and function expressions
  - Added support for ES6 classes and old-style constructor functions
  - Added prototype-based method detection
  - Added JSDoc documentation extraction
  - Added source location tracking
- [ ] TODO: Add tests for both parsers
- [ ] TODO: Add error handling for malformed code
- [ ] TODO: Add support for more JavaScript patterns (e.g., object methods, getters/setters)

Next Steps:
1. Write unit tests for both parsers
2. Add error handling for edge cases
3. Enhance JavaScript parser to handle more patterns
4. Add documentation for supported code patterns

## [2024-02-13] Multi-Language Parser Support Planning
### Phase Overview
Planning to extend the code analyzer to support multiple programming languages and file formats.

### Planned Language Support
1. **YAML Parser (First Priority)**
   - [ ] Add YAML parser using js-yaml
   - [ ] Create YAML-specific analysis types
   - [ ] Add structure extraction (keys, values, arrays)
   - [ ] Add documentation comment support
   - [ ] Add validation for common YAML patterns

2. **Future Language Support**
   - [ ] Create base parser interface
   - [ ] Add Python support using tree-sitter
   - [ ] Add Java support
   - [ ] Add support for config files (.env, .ini)

### Implementation Strategy
1. **Phase 1: Base Interface**
   - [ ] Create ILanguageParser interface
   - [ ] Define common analysis types
   - [ ] Refactor existing TS/JS parsers

2. **Phase 2: YAML Implementation**
   - [ ] Set up YAML parser
   - [ ] Add YAML-specific analysis
   - [ ] Add tests

3. **Phase 3: Additional Languages**
   - [ ] Implement language detection
   - [ ] Add language-specific parsers
   - [ ] Add comprehensive tests

Next Steps:
1. Create base parser interface
2. Implement YAML parser
3. Add tests for new parsers
4. Document new language support

Dependencies to Add:
- js-yaml (YAML parsing)
- tree-sitter (for future language support)
- language-specific parsers as needed

## [2024-02-13] JavaScript Parsing Issues & Fixes
### Problem Overview
Identified issues with JavaScript file parsing using ts-morph:
- Error: `Cannot read properties of undefined (reading 'escapedName')`
- Root cause: Attempting to extract type information from untyped JavaScript files
- Affected files: main.js, visualizationModule.js

### Required Fixes
1. **TypeScript Configuration**
   - [ ] Update tsconfig.json to properly handle JavaScript files
   - [ ] Add allowJs and checkJs compiler options
   - [ ] Configure JSDoc support for better type inference

2. **Parser Robustness**
   - [ ] Add error handling for missing type information
   - [ ] Implement fallback type extraction for JavaScript files
   - [ ] Add graceful degradation for untyped functions

3. **Testing & Validation**
   - [ ] Add test cases for JavaScript files
   - [ ] Verify parsing of different JavaScript patterns
   - [ ] Add error recovery mechanisms

Next Steps:
1. Update TypeScript configuration
2. Enhance JavaScript parser resilience
3. Add comprehensive error handling
4. Test with various JavaScript files

Dependencies to Update:
- ts-morph configuration
- JavaScript parsing logic
- Error handling mechanisms

## Token Optimization Sprint - [Current Date]

### Objective
Optimize token usage to reduce API costs while maintaining analysis quality

### Changes Made
1. Context Optimization
   - Implemented code cleaning to remove comments and console logs
   - Smart function/class body truncation
   - Whitespace normalization
   - Added optimization metadata

2. Prompt Optimization
   - Streamlined system prompt while maintaining guidelines
   - Condensed analysis prompts to focus on essentials
   - Simplified JSON response schemas

### Status
✅ Implemented token-efficient context processing
✅ Updated prompts for better token economy
🔄 Ready for testing with real codebase

### Next Steps
- Monitor token usage in production
- Fine-tune optimization parameters if needed
- Gather metrics on analysis quality vs token reduction

## [2024-02-14] Frontend Enhancements for OpenAI Integration
### Changes Made
1. Updated Frontend Interfaces
   - Enhanced CodeFunction and CodeClass interfaces with documentation and location info
   - Added better type definitions for analysis response
   - Improved error handling in API response processing

2. Enhanced Relationship Visualization
   - Added tooltips for better information display
   - Improved Mermaid diagram readability with descriptions
   - Added hover effects and visual feedback
   - Enhanced error handling for diagram rendering

3. UI/UX Improvements
   - Added loading states and progress feedback
   - Enhanced error messages with more context
   - Added success notifications with analysis stats
   - Improved component relationship visualization

### Status
✅ Frontend interfaces updated to match OpenAI client
✅ Enhanced visualization components
✅ Improved error handling and user feedback
🔄 Ready for testing with real codebase analysis

### Next Steps
1. Test with large codebases to verify performance
2. Add loading progress indicators for long analyses
3. Implement caching for analyzed components
4. Add export functionality for documentation

## [2024-02-14] Multi-Language Parser Expansion Plan

### Phase 1: JavaScript Enhancement
Current Status: Basic JS parsing with ts-morph, needs improvement
Goals:
- Enhance JavaScript parsing capabilities
- Add support for modern JS features (ES6+)
- Handle JSX/React components
- Support CommonJS and ES Modules
- Parse JS documentation formats (JSDoc)

### Phase 2: Python Implementation
Goals:
- Create new PythonParser class
- Implement AST parsing using `ast` module
- Support Python docstrings
- Handle type hints (PEP 484)
- Parse decorators and class properties
- Support Python modules and packages

### Phase 3: HTML/Template Implementation
Goals:
- Create new HTMLParser class
- Parse HTML structure and attributes
- Support template languages (EJS, Handlebars)
- Extract inline scripts and styles
- Handle web components
- Support meta tags and SEO elements

### Technical Requirements
1. Parser Interface Updates:
   - Extend ILanguageParser interface
   - Add language-specific metadata
   - Implement consistent error handling
   - Add progress reporting

2. Dependencies to Add:
   - Python: python-shell or node-python
   - HTML: cheerio or parse5
   - Enhanced JS: @babel/parser
   - Testing: jest with language-specific fixtures

3. Integration Points:
   - Update projectAnalyzer.ts
   - Modify frontend components
   - Enhance visualization for new languages
   - Update documentation generation

### Implementation Priorities
1. JavaScript Enhancement (1-2 weeks)
   - Most urgent as it's partially implemented
   - High impact for React/Node.js projects
   
2. Python Support (2-3 weeks)
   - Second priority for data science/backend projects
   - Requires new parser implementation
   
3. HTML Support (1-2 weeks)
   - Final phase for full-stack analysis
   - Focus on template integration

Next Steps:
1. Get senior dev review of this plan
2. Set up testing infrastructure
3. Begin with JavaScript enhancements
4. Create detailed specs for each parser

Dependencies to Add:
```json
{
  "devDependencies": {
    "@babel/parser": "^7.x",
    "@babel/traverse": "^7.x",
    "cheerio": "^1.x",
    "parse5": "^7.x",
    "python-shell": "^3.x",
    "jest": "^29.x"
  }
}
```

Files to Modify:
1. src/codeAnalyzer/languageParsers/
   - Enhance jsParser.ts
   - Create pythonParser.ts
   - Create htmlParser.ts
   - Update ILanguageParser.ts

2. src/codeAnalyzer/
   - Update projectAnalyzer.ts
   - Modify index.ts
   - Update types.ts

3. frontend/src/components/
   - Update CodeAnalyzer.tsx
   - Enhance visualization components

4. Testing
   - Create __tests__ directory
   - Add language-specific test fixtures
   - Implement integration tests

## [2024-02-14] Parser Upgrade Progress - Phase 1

### Completed Tasks:
1. ✅ Installed Babel dependencies:
   - @babel/parser
   - @babel/traverse
   - @babel/types

2. ✅ Created new parser implementations:
   - Created BabelParser class for JavaScript files
   - Updated TypeScript parser to use ILanguageParser interface
   - Created ParserRegistry for managing multiple parsers

3. ✅ Enhanced type definitions:
   - Added ILanguageParser interface
   - Added new fields for Babel parser support
   - Made body fields optional to support codeSnippet alternative

### Next Steps:
1. Test the new Babel parser with various JavaScript files
2. Add support for more JavaScript patterns:
   - Function expressions
   - Object methods
   - Class fields and decorators
3. Enhance type inference for parameters and return types
4. Add comprehensive tests for all parsers

Current Status: Basic Babel parser implementation complete, ready for testing
Next Phase: Begin Python parser implementation using python-shell
</file>

<file path="docs/architecture.md">
<!-- Architecture decisions and design notes -->
</file>

<file path="frontend/.gitignore">
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

node_modules
dist
dist-ssr
*.local

# Editor directories and files
.vscode/*
!.vscode/extensions.json
.idea
.DS_Store
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?
</file>

<file path="frontend/eslint.config.js">
import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'
import tseslint from 'typescript-eslint'
export default tseslint.config(
  { ignores: ['dist'] },
  {
    extends: [js.configs.recommended, ...tseslint.configs.recommended],
    files: ['**/*.{ts,tsx}'],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
    },
    plugins: {
      'react-hooks': reactHooks,
      'react-refresh': reactRefresh,
    },
    rules: {
      ...reactHooks.configs.recommended.rules,
      'react-refresh/only-export-components': [
        'warn',
        { allowConstantExport: true },
      ],
    },
  },
)
</file>

<file path="frontend/index.html">
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Vite + React + TS</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>
</file>

<file path="frontend/package.json">
{
  "name": "frontend",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc -b && vite build",
    "lint": "eslint .",
    "preview": "vite preview"
  },
  "dependencies": {
    "@chakra-ui/react": "^2.7.1",
    "@emotion/react": "^11.11.1",
    "@emotion/styled": "^11.11.0",
    "@types/js-yaml": "^4.0.9",
    "axios": "^1.7.9",
    "framer-motion": "^10.12.18",
    "js-yaml": "^4.1.0",
    "mermaid": "^10.8.0",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-icons": "^5.0.1",
    "react-markdown": "^9.0.3",
    "react-router-dom": "^6.22.0",
    "react-syntax-highlighter": "^15.6.1"
  },
  "devDependencies": {
    "@types/react": "^18.2.55",
    "@types/react-dom": "^18.2.19",
    "@types/react-syntax-highlighter": "^15.5.13",
    "@vitejs/plugin-react": "^4.3.4",
    "eslint": "^8.56.0",
    "eslint-plugin-react-hooks": "^4.6.0",
    "eslint-plugin-react-refresh": "^0.4.5",
    "typescript": "^5.3.3",
    "vite": "^5.4.14"
  }
}
</file>

<file path="frontend/public/vite.svg">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="iconify iconify--logos" width="31.88" height="32" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 257"><defs><linearGradient id="IconifyId1813088fe1fbc01fb466" x1="-.828%" x2="57.636%" y1="7.652%" y2="78.411%"><stop offset="0%" stop-color="#41D1FF"></stop><stop offset="100%" stop-color="#BD34FE"></stop></linearGradient><linearGradient id="IconifyId1813088fe1fbc01fb467" x1="43.376%" x2="50.316%" y1="2.242%" y2="89.03%"><stop offset="0%" stop-color="#FFEA83"></stop><stop offset="8.333%" stop-color="#FFDD35"></stop><stop offset="100%" stop-color="#FFA800"></stop></linearGradient></defs><path fill="url(#IconifyId1813088fe1fbc01fb466)" d="M255.153 37.938L134.897 252.976c-2.483 4.44-8.862 4.466-11.382.048L.875 37.958c-2.746-4.814 1.371-10.646 6.827-9.67l120.385 21.517a6.537 6.537 0 0 0 2.322-.004l117.867-21.483c5.438-.991 9.574 4.796 6.877 9.62Z"></path><path fill="url(#IconifyId1813088fe1fbc01fb467)" d="M185.432.063L96.44 17.501a3.268 3.268 0 0 0-2.634 3.014l-5.474 92.456a3.268 3.268 0 0 0 3.997 3.378l24.777-5.718c2.318-.535 4.413 1.507 3.936 3.838l-7.361 36.047c-.495 2.426 1.782 4.5 4.151 3.78l15.304-4.649c2.372-.72 4.652 1.36 4.15 3.788l-11.698 56.621c-.732 3.542 3.979 5.473 5.943 2.437l1.313-2.028l72.516-144.72c1.215-2.423-.88-5.186-3.54-4.672l-25.505 4.922c-2.396.462-4.435-1.77-3.759-4.114l16.646-57.705c.677-2.35-1.37-4.583-3.769-4.113Z"></path></svg>
</file>

<file path="frontend/README.md">
# React + TypeScript + Vite

This template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.

Currently, two official plugins are available:

- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react/README.md) uses [Babel](https://babeljs.io/) for Fast Refresh
- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh

## Expanding the ESLint configuration

If you are developing a production application, we recommend updating the configuration to enable type aware lint rules:

- Configure the top-level `parserOptions` property like this:

```js
export default tseslint.config({
  languageOptions: {
    // other options...
    parserOptions: {
      project: ['./tsconfig.node.json', './tsconfig.app.json'],
      tsconfigRootDir: import.meta.dirname,
    },
  },
})
```

- Replace `tseslint.configs.recommended` to `tseslint.configs.recommendedTypeChecked` or `tseslint.configs.strictTypeChecked`
- Optionally add `...tseslint.configs.stylisticTypeChecked`
- Install [eslint-plugin-react](https://github.com/jsx-eslint/eslint-plugin-react) and update the config:

```js
// eslint.config.js
import react from 'eslint-plugin-react'

export default tseslint.config({
  // Set the react version
  settings: { react: { version: '18.3' } },
  plugins: {
    // Add the react plugin
    react,
  },
  rules: {
    // other rules...
    // Enable its recommended rules
    ...react.configs.recommended.rules,
    ...react.configs['jsx-runtime'].rules,
  },
})
```
</file>

<file path="frontend/src/App.css">
#root {
  max-width: 1280px;
  margin: 0 auto;
  padding: 2rem;
  text-align: center;
}
.logo {
  height: 6em;
  padding: 1.5em;
  will-change: filter;
  transition: filter 300ms;
}
.logo:hover {
  filter: drop-shadow(0 0 2em #646cffaa);
}
.logo.react:hover {
  filter: drop-shadow(0 0 2em #61dafbaa);
}
@keyframes logo-spin {
  from {
    transform: rotate(0deg);
  }
  to {
    transform: rotate(360deg);
  }
}
@media (prefers-reduced-motion: no-preference) {
  a:nth-of-type(2) .logo {
    animation: logo-spin infinite 20s linear;
  }
}
.card {
  padding: 2em;
}
.read-the-docs {
  color: #888;
}
</file>

<file path="frontend/src/App.tsx">
import { ChakraProvider } from '@chakra-ui/react'
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom'
import Navbar from './components/Navbar'
import CodeAnalyzer from './components/CodeAnalyzer'
import Documentation from './components/Documentation'
function App() {
  return (
    <ChakraProvider>
      <Router>
        <Navbar />
        <main style={{ padding: '2rem' }}>
          <Routes>
            <Route path="/" element={<CodeAnalyzer />} />
            <Route path="/docs" element={<Documentation />} />
          </Routes>
        </main>
      </Router>
    </ChakraProvider>
  )
}
export default App
</file>

<file path="frontend/src/assets/react.svg">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="iconify iconify--logos" width="35.93" height="32" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 228"><path fill="#00D8FF" d="M210.483 73.824a171.49 171.49 0 0 0-8.24-2.597c.465-1.9.893-3.777 1.273-5.621c6.238-30.281 2.16-54.676-11.769-62.708c-13.355-7.7-35.196.329-57.254 19.526a171.23 171.23 0 0 0-6.375 5.848a155.866 155.866 0 0 0-4.241-3.917C100.759 3.829 77.587-4.822 63.673 3.233C50.33 10.957 46.379 33.89 51.995 62.588a170.974 170.974 0 0 0 1.892 8.48c-3.28.932-6.445 1.924-9.474 2.98C17.309 83.498 0 98.307 0 113.668c0 15.865 18.582 31.778 46.812 41.427a145.52 145.52 0 0 0 6.921 2.165a167.467 167.467 0 0 0-2.01 9.138c-5.354 28.2-1.173 50.591 12.134 58.266c13.744 7.926 36.812-.22 59.273-19.855a145.567 145.567 0 0 0 5.342-4.923a168.064 168.064 0 0 0 6.92 6.314c21.758 18.722 43.246 26.282 56.54 18.586c13.731-7.949 18.194-32.003 12.4-61.268a145.016 145.016 0 0 0-1.535-6.842c1.62-.48 3.21-.974 4.76-1.488c29.348-9.723 48.443-25.443 48.443-41.52c0-15.417-17.868-30.326-45.517-39.844Zm-6.365 70.984c-1.4.463-2.836.91-4.3 1.345c-3.24-10.257-7.612-21.163-12.963-32.432c5.106-11 9.31-21.767 12.459-31.957c2.619.758 5.16 1.557 7.61 2.4c23.69 8.156 38.14 20.213 38.14 29.504c0 9.896-15.606 22.743-40.946 31.14Zm-10.514 20.834c2.562 12.94 2.927 24.64 1.23 33.787c-1.524 8.219-4.59 13.698-8.382 15.893c-8.067 4.67-25.32-1.4-43.927-17.412a156.726 156.726 0 0 1-6.437-5.87c7.214-7.889 14.423-17.06 21.459-27.246c12.376-1.098 24.068-2.894 34.671-5.345a134.17 134.17 0 0 1 1.386 6.193ZM87.276 214.515c-7.882 2.783-14.16 2.863-17.955.675c-8.075-4.657-11.432-22.636-6.853-46.752a156.923 156.923 0 0 1 1.869-8.499c10.486 2.32 22.093 3.988 34.498 4.994c7.084 9.967 14.501 19.128 21.976 27.15a134.668 134.668 0 0 1-4.877 4.492c-9.933 8.682-19.886 14.842-28.658 17.94ZM50.35 144.747c-12.483-4.267-22.792-9.812-29.858-15.863c-6.35-5.437-9.555-10.836-9.555-15.216c0-9.322 13.897-21.212 37.076-29.293c2.813-.98 5.757-1.905 8.812-2.773c3.204 10.42 7.406 21.315 12.477 32.332c-5.137 11.18-9.399 22.249-12.634 32.792a134.718 134.718 0 0 1-6.318-1.979Zm12.378-84.26c-4.811-24.587-1.616-43.134 6.425-47.789c8.564-4.958 27.502 2.111 47.463 19.835a144.318 144.318 0 0 1 3.841 3.545c-7.438 7.987-14.787 17.08-21.808 26.988c-12.04 1.116-23.565 2.908-34.161 5.309a160.342 160.342 0 0 1-1.76-7.887Zm110.427 27.268a347.8 347.8 0 0 0-7.785-12.803c8.168 1.033 15.994 2.404 23.343 4.08c-2.206 7.072-4.956 14.465-8.193 22.045a381.151 381.151 0 0 0-7.365-13.322Zm-45.032-43.861c5.044 5.465 10.096 11.566 15.065 18.186a322.04 322.04 0 0 0-30.257-.006c4.974-6.559 10.069-12.652 15.192-18.18ZM82.802 87.83a323.167 323.167 0 0 0-7.227 13.238c-3.184-7.553-5.909-14.98-8.134-22.152c7.304-1.634 15.093-2.97 23.209-3.984a321.524 321.524 0 0 0-7.848 12.897Zm8.081 65.352c-8.385-.936-16.291-2.203-23.593-3.793c2.26-7.3 5.045-14.885 8.298-22.6a321.187 321.187 0 0 0 7.257 13.246c2.594 4.48 5.28 8.868 8.038 13.147Zm37.542 31.03c-5.184-5.592-10.354-11.779-15.403-18.433c4.902.192 9.899.29 14.978.29c5.218 0 10.376-.117 15.453-.343c-4.985 6.774-10.018 12.97-15.028 18.486Zm52.198-57.817c3.422 7.8 6.306 15.345 8.596 22.52c-7.422 1.694-15.436 3.058-23.88 4.071a382.417 382.417 0 0 0 7.859-13.026a347.403 347.403 0 0 0 7.425-13.565Zm-16.898 8.101a358.557 358.557 0 0 1-12.281 19.815a329.4 329.4 0 0 1-23.444.823c-7.967 0-15.716-.248-23.178-.732a310.202 310.202 0 0 1-12.513-19.846h.001a307.41 307.41 0 0 1-10.923-20.627a310.278 310.278 0 0 1 10.89-20.637l-.001.001a307.318 307.318 0 0 1 12.413-19.761c7.613-.576 15.42-.876 23.31-.876H128c7.926 0 15.743.303 23.354.883a329.357 329.357 0 0 1 12.335 19.695a358.489 358.489 0 0 1 11.036 20.54a329.472 329.472 0 0 1-11 20.722Zm22.56-122.124c8.572 4.944 11.906 24.881 6.52 51.026c-.344 1.668-.73 3.367-1.15 5.09c-10.622-2.452-22.155-4.275-34.23-5.408c-7.034-10.017-14.323-19.124-21.64-27.008a160.789 160.789 0 0 1 5.888-5.4c18.9-16.447 36.564-22.941 44.612-18.3ZM128 90.808c12.625 0 22.86 10.235 22.86 22.86s-10.235 22.86-22.86 22.86s-22.86-10.235-22.86-22.86s10.235-22.86 22.86-22.86Z"></path></svg>
</file>

<file path="frontend/src/components/CodeAnalyzer.tsx">
import { useState } from 'react'
import {
  Box,
  Button,
  VStack,
  Text,
  Heading,
  Flex,
  Container,
  Input,
  useToast,
  Code,
  Badge,
  SimpleGrid,
  Accordion,
  AccordionItem,
  AccordionButton,
  AccordionPanel,
  AccordionIcon,
  Grid,
  GridItem,
  HStack,
  Divider,
  useColorModeValue,
  UnorderedList,
  ListItem,
  Wrap,
  WrapItem
} from '@chakra-ui/react'
import { Prism as SyntaxHighlighter } from 'react-syntax-highlighter'
import { tomorrow } from 'react-syntax-highlighter/dist/esm/styles/prism'
import ReactMarkdown from 'react-markdown'
import axios from 'axios'
import { ComponentAnalysis } from '../../../src/mcp/openaiClient'
import RelationshipVisualizer from './RelationshipVisualizer'
import MermaidDiagram from './MermaidDiagram'
// Define interfaces for our code analysis
interface Parameter {
  name: string;
  type: string;
  description: string;
}
interface CodeFunction {
  name: string;
  description: string;
  parameters: Parameter[];
  returnType: string;
  body: string;
  fileName: string;
  documentation?: string;
  location?: {
    file: string;
    startLine: number;
    endLine: number;
  };
}
interface CodeClass {
  name: string;
  description: string;
  methods: CodeFunction[];
  properties: Array<{
    name: string;
    type: string;
    description: string;
    documentation?: string;
  }>;
  fileName: string;
  documentation?: string;
  location?: {
    file: string;
    startLine: number;
    endLine: number;
  };
}
interface AnalysisResponse {
  codeOutput: {
    functions: CodeFunction[];
    classes: CodeClass[];
  };
  aiAnalysis: {
    overview: {
      description: string;
      architecture: string;
      mainComponents: string[];
      dataFlow: string;
      technicalStack: string[];
    };
    components: ComponentAnalysis[];
    dependencies: {
      nodes: Array<{
        id: string;
        type: string;
        description: string;
      }>;
      edges: Array<{
        from: string;
        to: string;
        type: string;
        description: string;
      }>;
    };
  };
}
const CodeAnalyzer = () => {
  const [folder, setFolder] = useState<string>('')
  const [loading, setLoading] = useState(false)
  const [analysisData, setAnalysisData] = useState<AnalysisResponse | null>(null)
  const toast = useToast()
  const bgColor = useColorModeValue('gray.50', 'gray.700')
  const borderColor = useColorModeValue('gray.200', 'gray.600')
  const codeBgColor = useColorModeValue('white', 'gray.800')
  // Add this helper function for safe array access
  const safeArray = <T,>(arr: T[] | undefined | null): T[] => {
    return Array.isArray(arr) ? arr : [];
  };
  // Add this helper function for safe object access
  const safeObject = <T,>(obj: T | undefined | null): T => {
    return obj || {} as T;
  };
  // Add this function to generate the Mermaid diagram
  const generateDependencyDiagram = (dependencies: AnalysisResponse['aiAnalysis']['dependencies']) => {
    let diagram = 'graph TD;\n';
    // Add styling
    diagram += `%% Styling\n`;
    diagram += `classDef default fill:#f9f9f9,stroke:#333,stroke-width:1px;\n`;
    diagram += `classDef function fill:#e3f2fd,stroke:#1976d2,stroke-width:2px;\n`;
    diagram += `classDef class fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px;\n`;
    diagram += `classDef component fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px;\n`;
    diagram += `classDef module fill:#fff3e0,stroke:#f57c00,stroke-width:2px;\n\n`;
    // Add nodes
    dependencies.nodes.forEach(node => {
      diagram += `${node.id}["${node.type}: ${node.id}"];\n`;
      diagram += `class ${node.id} ${node.type};\n`;
    });
    // Add edges
    dependencies.edges.forEach(edge => {
      diagram += `${edge.from} -->|${edge.type}| ${edge.to};\n`;
    });
    return diagram;
  };
  const runAnalysis = async () => {
    if (!folder.trim()) {
      toast({
        title: 'No folder provided',
        description: 'Please enter a folder path to analyze.',
        status: 'error',
        duration: 3000,
        isClosable: true,
      })
      return
    }
    console.log('🔍 Starting analysis for folder:', folder)
    setLoading(true)
    try {
      const response = await axios.post<AnalysisResponse>('http://localhost:3000/api/analyze', {
        folder
      });
      if (!response.data.aiAnalysis) {
        throw new Error('Invalid analysis response format');
      }
      setAnalysisData(response.data);
      toast({
        title: 'Analysis complete',
        description: `Analyzed ${response.data.codeOutput.functions.length} functions and ${response.data.codeOutput.classes.length} classes`,
        status: 'success',
        duration: 3000,
        isClosable: true,
      })
    } catch (error: any) {
      console.error('❌ Analysis error:', error)
      toast({
        title: 'Error running analysis',
        description: error.response?.data?.error || error.message || 'An error occurred',
        status: 'error',
        duration: 5000,
        isClosable: true,
      })
    } finally {
      setLoading(false)
      console.log('✅ Analysis process completed')
    }
  }
  const renderAnalysisPanel = (analysis: ComponentAnalysis | undefined) => {
    if (!analysis) return null;
    return (
      <Box p={4} bg={bgColor} borderRadius="md" borderWidth="1px" borderColor={borderColor}>
        <VStack align="stretch" spacing={4}>
          <HStack>
            <Badge colorScheme={analysis.type === 'class' ? 'purple' : 'blue'}>
              {analysis.type}
            </Badge>
            <Heading size="md">{analysis.name}</Heading>
          </HStack>
          <Text>{analysis.description}</Text>
          <Box>
            <Heading size="sm" mb={2}>Implementation</Heading>
            <Code p={2} borderRadius="md" display="block" whiteSpace="pre">
              {analysis.implementation}
            </Code>
          </Box>
          <Box>
            <Heading size="sm" mb={2}>Usage</Heading>
            <Text>{analysis.usage}</Text>
          </Box>
          {analysis.parameters && analysis.parameters.length > 0 && (
            <Box>
              <Heading size="sm" mb={2}>Parameters</Heading>
              <VStack align="stretch">
                {analysis.parameters.map((param, index) => (
                  <Box key={`${analysis.name}-param-${index}`} p={2} bg={codeBgColor} borderRadius="md">
                    <Text fontWeight="bold">{param.name}: {param.type}</Text>
                    <Text>{param.description}</Text>
                  </Box>
                ))}
              </VStack>
            </Box>
          )}
          {analysis.returns && (
            <Box>
              <Heading size="sm" mb={2}>Returns</Heading>
              <Box p={2} bg={codeBgColor} borderRadius="md">
                <Text fontWeight="bold">{analysis.returns.type}</Text>
                <Text>{analysis.returns.description}</Text>
              </Box>
            </Box>
          )}
          {analysis.bestPractices && analysis.bestPractices.length > 0 && (
            <Box>
              <Heading size="sm" mb={2}>Best Practices</Heading>
              <VStack align="stretch">
                {analysis.bestPractices.map((practice, index) => (
                  <Text key={`${analysis.name}-practice-${index}`}>• {practice}</Text>
                ))}
              </VStack>
            </Box>
          )}
          {analysis.relationships && (
            <RelationshipVisualizer analysis={analysis} />
          )}
        </VStack>
      </Box>
    );
  };
  return (
    <Container maxW="container.xl">
      <VStack spacing={8} align="stretch">
        <Box>
          <Heading size="lg" mb={4}>Code Analyzer</Heading>
          <Text mb={4}>Enter the full folder path to analyze and generate documentation.</Text>
          <Flex gap={4} mb={8}>
            <Input 
              placeholder='Enter full folder path (e.g., C:\path\to\folder)' 
              value={folder}
              onChange={(e) => setFolder(e.target.value)}
            />
            <Button
              colorScheme="green"
              onClick={runAnalysis}
              isLoading={loading}
              loadingText="Analyzing..."
              disabled={loading || !folder.trim()}
              _disabled={{ opacity: 0.6, cursor: 'not-allowed' }}
            >
              Run Analysis
            </Button>
          </Flex>
          {folder && (
            <Text fontSize="sm" color="gray.600" mb={4}>
              Selected folder: {folder}
            </Text>
          )}
        </Box>
        {analysisData && (
          <VStack spacing={6} align="stretch">
            {/* Overview Section */}
            <Box>
              <Heading size="md" mb={4}>System Overview</Heading>
              <VStack align="stretch" spacing={4} p={4} bg={bgColor} borderRadius="md" borderWidth="1px">
                <Text><strong>Description:</strong> {safeObject(analysisData.aiAnalysis.overview).description || 'No description available'}</Text>
                <Text><strong>Architecture:</strong> {safeObject(analysisData.aiAnalysis.overview).architecture || 'No architecture details available'}</Text>
                <Box>
                  <Text fontWeight="bold">Main Components:</Text>
                  <UnorderedList>
                    {safeArray(safeObject(analysisData.aiAnalysis.overview).mainComponents).map((comp, i) => (
                      <ListItem key={i}>{comp}</ListItem>
                    ))}
                  </UnorderedList>
                </Box>
                <Text><strong>Data Flow:</strong> {safeObject(analysisData.aiAnalysis.overview).dataFlow || 'No data flow information available'}</Text>
                <Box>
                  <Text fontWeight="bold">Tech Stack:</Text>
                  <Wrap>
                    {safeArray(safeObject(analysisData.aiAnalysis.overview).technicalStack).map((tech, i) => (
                      <WrapItem key={i}>
                        <Badge colorScheme="blue">{tech}</Badge>
                      </WrapItem>
                    ))}
                  </Wrap>
                </Box>
              </VStack>
            </Box>
            {/* Components Analysis */}
            <Box>
              <Heading size="md" mb={4}>Components</Heading>
              <SimpleGrid columns={[1, null, 2]} spacing={6}>
                {safeArray(analysisData.aiAnalysis.components).map((component, index) => (
                  <Box key={index}>
                    {renderAnalysisPanel(component)}
                  </Box>
                ))}
              </SimpleGrid>
            </Box>
            {/* Dependencies Graph */}
            <Box>
              <Heading size="md" mb={4}>Dependencies</Heading>
              <Box p={4} bg={bgColor} borderRadius="md" borderWidth="1px">
                <MermaidDiagram
                  chart={generateDependencyDiagram(safeObject(analysisData.aiAnalysis).dependencies)}
                  config={{
                    theme: useColorModeValue('default', 'dark'),
                    flowchart: {
                      curve: 'monotoneX',
                      padding: 20
                    }
                  }}
                />
              </Box>
            </Box>
          </VStack>
        )}
      </VStack>
    </Container>
  )
}
export default CodeAnalyzer
</file>

<file path="frontend/src/components/Documentation.tsx">
import { Box, Heading, Text, VStack, Flex, Tag, Container } from '@chakra-ui/react'
import { Light as SyntaxHighlighter } from 'react-syntax-highlighter'
import typescript from 'react-syntax-highlighter/dist/esm/languages/hljs/typescript'
import { docco } from 'react-syntax-highlighter/dist/esm/styles/hljs'
SyntaxHighlighter.registerLanguage('typescript', typescript)
const Documentation = () => {
  // This is a placeholder. In a real app, we'd fetch this from the backend
  const docs = {
    functions: [
      {
        name: 'analyzeProject',
        description: 'Analyzes a project directory and extracts code information.',
        params: [
          {
            name: 'folder',
            type: 'string',
            description: 'The path to the project folder to analyze'
          }
        ],
        returnType: 'Promise<AnalysisResult>',
        example: `const result = await analyzeProject('./my-project');
console.log(result.functions);`
      }
    ]
  }
  return (
    <Container maxW="container.xl">
      <VStack spacing={8} align="stretch">
        <Box>
          <Heading size="lg" mb={4}>Documentation</Heading>
          <Text mb={8}>Generated documentation for your codebase.</Text>
        </Box>
        <Box>
          <Heading size="md" mb={4}>Functions</Heading>
          <VStack spacing={6} align="stretch">
            {docs.functions.map((func, index) => (
              <Box key={index} p={6} borderRadius="lg" borderWidth={1} borderColor="gray.200">
                <Flex gap={2} mb={4} align="center">
                  <Heading size="sm">{func.name}</Heading>
                  <Tag colorScheme="blue" size="sm">{func.returnType}</Tag>
                </Flex>
                <Text mb={4}>{func.description}</Text>
                <Box mb={4}>
                  <Text fontWeight="bold" mb={2}>Parameters:</Text>
                  <VStack align="stretch" pl={4}>
                    {func.params.map((param, pIndex) => (
                      <Flex key={pIndex} gap={2}>
                        <Text color="blue.500">{param.name}</Text>
                        <Text color="gray.500">({param.type})</Text>
                        <Text>- {param.description}</Text>
                      </Flex>
                    ))}
                  </VStack>
                </Box>
                <Box>
                  <Text fontWeight="bold" mb={2}>Example:</Text>
                  <Box borderRadius="md" overflow="hidden">
                    <SyntaxHighlighter
                      language="typescript"
                      style={docco}
                      customStyle={{ margin: 0 }}
                    >
                      {func.example}
                    </SyntaxHighlighter>
                  </Box>
                </Box>
              </Box>
            ))}
          </VStack>
        </Box>
      </VStack>
    </Container>
  )
}
export default Documentation
</file>

<file path="frontend/src/components/MermaidDiagram.tsx">
import React, { useEffect, useRef } from 'react';
import mermaid from 'mermaid';
interface MermaidDiagramProps {
  chart: string;
  config?: {
    theme?: 'default' | 'dark' | 'neutral' | 'forest';
    flowchart?: {
      curve?: 'basis' | 'linear' | 'cardinal' | 'monotoneX';
      padding?: number;
      rankSpacing?: number;
      nodeSpacing?: number;
      htmlLabels?: boolean;
    };
  };
}
const MermaidDiagram: React.FC<MermaidDiagramProps> = ({ chart, config }) => {
  const elementRef = useRef<HTMLDivElement>(null);
  useEffect(() => {
    // Initialize mermaid with enhanced config
    mermaid.initialize({
      startOnLoad: true,
      theme: config?.theme || 'default',
      fontFamily: 'arial',
      fontSize: 14,
      flowchart: {
        curve: 'basis',
        padding: config?.flowchart?.padding || 20,
        rankSpacing: config?.flowchart?.rankSpacing || 100,
        nodeSpacing: config?.flowchart?.nodeSpacing || 100,
        htmlLabels: config?.flowchart?.htmlLabels ?? true,
        useMaxWidth: true,
        diagramPadding: 8
      }
    });
    // Render the diagram with error handling
    const renderDiagram = async () => {
      if (elementRef.current) {
        try {
          elementRef.current.innerHTML = '';
          // Preprocess the chart to simplify complex relationships
          const processedChart = chart
            // Clean up node definitions
            .replace(/\["/g, '[')
            .replace(/"\]/g, ']')
            // Fix edge syntax: convert -->-- to -->
            .replace(/-->\s*--/g, '-->')
            // Fix any remaining edge labels
            .replace(/\|(\w+)\|/g, '|$1|')
            // Ensure proper line endings
            .split('\n')
            .map(line => line.trim())
            .filter(Boolean)
            .join('\n');
          console.log('Processed chart:', processedChart);
          const { svg } = await mermaid.render('mermaid-diagram', processedChart);
          elementRef.current.innerHTML = svg;
          // Add zoom controls
          const svgElement = elementRef.current.querySelector('svg');
          if (svgElement) {
            svgElement.style.maxWidth = '100%';
            svgElement.style.height = 'auto';
            // Add viewBox if not present
            if (!svgElement.getAttribute('viewBox')) {
              const bbox = svgElement.getBBox();
              svgElement.setAttribute('viewBox', `${bbox.x} ${bbox.y} ${bbox.width} ${bbox.height}`);
            }
          }
        } catch (error) {
          console.error('Failed to render Mermaid diagram:', error);
          // Fallback to a simpler layout if rendering fails
          try {
            // Create a simplified TD (top-down) diagram
            const fallbackChart = `graph TD;
              ${chart.split('\n')
                .map(line => {
                  // Extract just the basic node connections
                  const match = line.match(/(\w+)\s*(?:-->|---|->)\s*(\w+)/);
                  if (match) {
                    return `${match[1]} --> ${match[2]}`;
                  }
                  return '';
                })
                .filter(Boolean)
                .join('\n')}`;
            console.log('Fallback chart:', fallbackChart);
            const { svg } = await mermaid.render('mermaid-diagram-fallback', fallbackChart);
            elementRef.current.innerHTML = svg;
          } catch (fallbackError) {
            console.error('Fallback rendering failed:', fallbackError);
            elementRef.current.innerHTML = `
              <div style="color: red; padding: 1rem; border: 1px solid red; border-radius: 4px;">
                <div style="font-weight: bold; margin-bottom: 0.5rem;">Failed to render diagram</div>
                <div style="margin-bottom: 1rem;">Original error: ${error instanceof Error ? error.message : String(error)}</div>
                <div style="font-size: 0.9em; color: #666;">
                  Please check the graph syntax. Common issues:
                  <ul style="margin-top: 0.5rem;">
                    <li>Invalid node names</li>
                    <li>Incorrect edge syntax</li>
                    <li>Missing semicolons</li>
                  </ul>
                </div>
              </div>
            `;
          }
        }
      }
    };
    renderDiagram();
  }, [chart, config]);
  return (
    <div 
      ref={elementRef} 
      style={{ 
        width: '100%', 
        overflowX: 'auto',
        padding: '1rem',
        background: config?.theme === 'dark' ? '#2D3748' : '#fff',
        borderRadius: '4px'
      }} 
    />
  );
};
export default MermaidDiagram;
</file>

<file path="frontend/src/components/Navbar.tsx">
import { Box, Container, Flex, Button, Heading } from '@chakra-ui/react'
import { Link as RouterLink } from 'react-router-dom'
const Navbar = () => {
  return (
    <Box bg="blue.500" color="white" py={4} mb={8}>
      <Container maxW="container.xl">
        <Flex justify="space-between" align="center">
          <Heading size="md">Code Doc Generator</Heading>
          <Flex gap={6}>
            <Button
              as={RouterLink}
              to="/"
              variant="ghost"
              color="white"
              _hover={{ bg: 'blue.600' }}
            >
              Analyzer
            </Button>
            <Button
              as={RouterLink}
              to="/docs"
              variant="ghost"
              color="white"
              _hover={{ bg: 'blue.600' }}
            >
              Documentation
            </Button>
          </Flex>
        </Flex>
      </Container>
    </Box>
  )
}
export default Navbar
</file>

<file path="frontend/src/components/RelationshipVisualizer.tsx">
import React from 'react';
import {
  Box,
  VStack,
  Heading,
  Text,
  Badge,
  Tabs,
  TabList,
  TabPanels,
  Tab,
  TabPanel,
  useColorModeValue,
  SimpleGrid,
  Flex,
  Icon,
  Tooltip,
} from '@chakra-ui/react';
import { ComponentAnalysis } from '../../../src/mcp/openaiClient';
import { FiArrowRight, FiArrowLeft, FiArrowUpRight, FiArrowDownRight } from 'react-icons/fi';
import MermaidDiagram from './MermaidDiagram';
interface RelationshipVisualizerProps {
  analysis: ComponentAnalysis;
}
const RelationshipVisualizer: React.FC<RelationshipVisualizerProps> = ({ analysis }) => {
  const bgColor = useColorModeValue('white', 'gray.800');
  const borderColor = useColorModeValue('gray.200', 'gray.600');
  const isDark = useColorModeValue(false, true);
  // Generate Mermaid diagram definition with enhanced styling
  const generateMermaidDiagram = () => {
    let diagram = 'graph TD;\n';
    // Add styling directives with improved visibility
    diagram += `%% Styling definitions\n`;
    diagram += `classDef default fill:#f9f9f9,stroke:#333,stroke-width:2px;\n`;
    diagram += `classDef main fill:#e1f5fe,stroke:#0288d1,stroke-width:3px;\n`;
    diagram += `classDef dependency fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px;\n`;
    diagram += `classDef dataflow fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px;\n\n`;
    // Add main component with enhanced styling and description
    diagram += `${analysis.name}["${analysis.type}: ${analysis.name}\n${analysis.description.slice(0, 50)}..."];\n`;
    diagram += `class ${analysis.name} main;\n\n`;
    // Add dependencies with improved styling and descriptions
    if (analysis.relationships?.dependencies) {
      diagram += `%% Dependencies\n`;
      analysis.relationships.dependencies.forEach((dep, index) => {
        const depId = `dep${index}`;
        diagram += `${depId}["${dep.type}: ${dep.name}\n${dep.description.slice(0, 30)}..."];\n`;
        diagram += `${depId} -->|${dep.type}| ${analysis.name};\n`;
        diagram += `class ${depId} dependency;\n`;
      });
    }
    // Add dependents with improved styling and descriptions
    if (analysis.relationships?.dependents) {
      diagram += `\n%% Dependents\n`;
      analysis.relationships.dependents.forEach((dep, index) => {
        const depId = `dependent${index}`;
        diagram += `${depId}["${dep.type}: ${dep.name}\n${dep.description.slice(0, 30)}..."];\n`;
        diagram += `${analysis.name} -->|${dep.type}| ${depId};\n`;
        diagram += `class ${depId} dependency;\n`;
      });
    }
    // Add data flow with improved styling and bidirectional arrows
    if (analysis.relationships?.dataFlow) {
      diagram += `\n%% Data Flow\n`;
      analysis.relationships.dataFlow.forEach((flow, index) => {
        const flowId = `flow${index}`;
        diagram += `${flowId}["${flow.component}\n${flow.description.slice(0, 30)}..."];\n`;
        if (flow.direction === 'in') {
          diagram += `${flowId} -->|data flow| ${analysis.name};\n`;
        } else if (flow.direction === 'out') {
          diagram += `${analysis.name} -->|data flow| ${flowId};\n`;
        } else {
          diagram += `${analysis.name} <--> ${flowId};\n`;
        }
        diagram += `class ${flowId} dataflow;\n`;
      });
    }
    return diagram;
  };
  const renderChakraRelationships = () => {
    return (
      <VStack spacing={6} align="stretch">
        {/* Dependencies Section */}
        {analysis.relationships?.dependencies && analysis.relationships.dependencies.length > 0 && (
          <Box>
            <Heading size="sm" mb={3}>Dependencies</Heading>
            <SimpleGrid columns={[1, 2, 3]} spacing={4}>
              {analysis.relationships.dependencies.map((dep, index) => (
                <Tooltip 
                  key={index}
                  label={dep.description}
                  placement="top"
                  hasArrow
                >
                  <Box 
                    p={4}
                    bg={bgColor}
                    borderRadius="md"
                    borderWidth="1px"
                    borderColor={borderColor}
                    cursor="help"
                    transition="all 0.2s"
                    _hover={{ shadow: "md" }}
                  >
                    <Flex align="center" gap={2}>
                      <Icon as={FiArrowUpRight} />
                      <Badge colorScheme="blue">{dep.type}</Badge>
                      <Text fontWeight="bold">{dep.name}</Text>
                    </Flex>
                    <Text mt={2} fontSize="sm" noOfLines={2}>{dep.description}</Text>
                  </Box>
                </Tooltip>
              ))}
            </SimpleGrid>
          </Box>
        )}
        {/* Dependents Section */}
        {analysis.relationships?.dependents && analysis.relationships.dependents.length > 0 && (
          <Box>
            <Heading size="sm" mb={3}>Dependents</Heading>
            <SimpleGrid columns={[1, 2, 3]} spacing={4}>
              {analysis.relationships.dependents.map((dep, index) => (
                <Tooltip 
                  key={index}
                  label={dep.description}
                  placement="top"
                  hasArrow
                >
                  <Box 
                    p={4}
                    bg={bgColor}
                    borderRadius="md"
                    borderWidth="1px"
                    borderColor={borderColor}
                    cursor="help"
                    transition="all 0.2s"
                    _hover={{ shadow: "md" }}
                  >
                    <Flex align="center" gap={2}>
                      <Icon as={FiArrowDownRight} />
                      <Badge colorScheme="purple">{dep.type}</Badge>
                      <Text fontWeight="bold">{dep.name}</Text>
                    </Flex>
                    <Text mt={2} fontSize="sm" noOfLines={2}>{dep.description}</Text>
                  </Box>
                </Tooltip>
              ))}
            </SimpleGrid>
          </Box>
        )}
        {/* Data Flow Section */}
        {analysis.relationships?.dataFlow && analysis.relationships.dataFlow.length > 0 && (
          <Box>
            <Heading size="sm" mb={3}>Data Flow</Heading>
            <SimpleGrid columns={[1, 2, 3]} spacing={4}>
              {analysis.relationships.dataFlow.map((flow, index) => (
                <Tooltip 
                  key={index}
                  label={flow.description}
                  placement="top"
                  hasArrow
                >
                  <Box 
                    p={4}
                    bg={bgColor}
                    borderRadius="md"
                    borderWidth="1px"
                    borderColor={borderColor}
                    cursor="help"
                    transition="all 0.2s"
                    _hover={{ shadow: "md" }}
                  >
                    <Flex align="center" gap={2}>
                      <Icon 
                        as={flow.direction === 'in' ? FiArrowLeft : 
                            flow.direction === 'out' ? FiArrowRight : 
                            FiArrowRight}
                      />
                      <Badge colorScheme="green">{flow.direction}</Badge>
                      <Text fontWeight="bold">{flow.component}</Text>
                    </Flex>
                    <Text mt={2} fontSize="sm" noOfLines={2}>{flow.description}</Text>
                  </Box>
                </Tooltip>
              ))}
            </SimpleGrid>
          </Box>
        )}
      </VStack>
    );
  };
  return (
    <Box mt={6}>
      <Heading size="md" mb={4}>Component Relationships</Heading>
      <Tabs variant="enclosed">
        <TabList>
          <Tab>Visual Layout</Tab>
          <Tab>Flow Diagram</Tab>
        </TabList>
        <TabPanels>
          <TabPanel>
            {renderChakraRelationships()}
          </TabPanel>
          <TabPanel>
            <Box 
              p={4} 
              bg={bgColor} 
              borderRadius="md" 
              borderWidth="1px" 
              borderColor={borderColor}
              overflow="auto"
            >
              <MermaidDiagram
                chart={generateMermaidDiagram()}
                config={{
                  theme: isDark ? 'dark' : 'default',
                  flowchart: {
                    curve: 'monotoneX',
                    padding: 20,
                    rankSpacing: 50,
                    nodeSpacing: 50,
                    htmlLabels: true,
                  },
                }}
              />
            </Box>
          </TabPanel>
        </TabPanels>
      </Tabs>
    </Box>
  );
};
export default RelationshipVisualizer;
</file>

<file path="frontend/src/index.css">
:root {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
  line-height: 1.5;
  font-weight: 400;
}
* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}
body {
  min-width: 320px;
  min-height: 100vh;
  background-color: #f7fafc;
}
/* Remove default button styles */
button {
  background: none;
  border: none;
  padding: 0;
  font: inherit;
  cursor: pointer;
  outline: inherit;
}
/* Smooth scrolling for the whole page */
html {
  scroll-behavior: smooth;
}
/* Better media defaults */
img, picture, video, canvas, svg {
  display: block;
  max-width: 100%;
}
/* Remove built-in form typography styles */
input, button, textarea, select {
  font: inherit;
}
/* Avoid text overflows */
p, h1, h2, h3, h4, h5, h6 {
  overflow-wrap: break-word;
}
/* Create a stacking context */
#root {
  isolation: isolate;
}
</file>

<file path="frontend/src/main.tsx">
import { StrictMode } from 'react'
import { createRoot } from 'react-dom/client'
import './index.css'
import App from './App.tsx'
createRoot(document.getElementById('root')!).render(
  <StrictMode>
    <App />
  </StrictMode>,
)
</file>

<file path="frontend/src/theme.ts">
import { extendTheme } from '@chakra-ui/react'
const theme = extendTheme({
  styles: {
    global: {
      body: {
        bg: 'gray.50',
      },
    },
  },
  components: {
    Button: {
      defaultProps: {
        colorScheme: 'blue',
      },
    },
  },
})
export default theme
</file>

<file path="frontend/src/types/mermaid-react.d.ts">
declare module 'mermaid-react' {
  import { FC } from 'react';
  interface MermaidConfig {
    theme?: 'default' | 'dark' | 'neutral' | 'forest';
    flowchart?: {
      curve?: 'basis' | 'linear' | 'cardinal' | 'monotoneX';
      padding?: number;
      rankSpacing?: number;
      nodeSpacing?: number;
      htmlLabels?: boolean;
    };
  }
  interface MermaidProps {
    key?: string;
    config?: MermaidConfig;
    children: string;
  }
  const Mermaid: FC<MermaidProps>;
  export default Mermaid;
}
</file>

<file path="frontend/src/vite-env.d.ts">
/// <reference types="vite/client" />
</file>

<file path="frontend/tsconfig.app.json">
{
  "compilerOptions": {
    "tsBuildInfoFile": "./node_modules/.tmp/tsconfig.app.tsbuildinfo",
    "target": "ES2020",
    "useDefineForClassFields": true,
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "isolatedModules": true,
    "moduleDetection": "force",
    "noEmit": true,
    "jsx": "react-jsx",

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true,
    "noUncheckedSideEffectImports": true
  },
  "include": ["src"]
}
</file>

<file path="frontend/tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2020",
    "useDefineForClassFields": true,
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "node",
    "allowImportingTsExtensions": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx",

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true,
    "allowSyntheticDefaultImports": true,
    "esModuleInterop": true,
    "forceConsistentCasingInFileNames": true
  },
  "include": ["src"],
  "references": [{ "path": "./tsconfig.node.json" }]
}
</file>

<file path="frontend/tsconfig.node.json">
{
  "compilerOptions": {
    "tsBuildInfoFile": "./node_modules/.tmp/tsconfig.node.tsbuildinfo",
    "target": "ES2022",
    "lib": ["ES2023"],
    "module": "ESNext",
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "isolatedModules": true,
    "moduleDetection": "force",
    "noEmit": true,

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true,
    "noUncheckedSideEffectImports": true
  },
  "include": ["vite.config.ts"]
}
</file>

<file path="frontend/vite.config.ts">
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'
// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
  resolve: {
    dedupe: [
      '@chakra-ui/react',
      '@emotion/react',
      '@emotion/styled',
      'react',
      'react-dom'
    ]
  },
  optimizeDeps: {
    include: ['@chakra-ui/react', '@emotion/react', '@emotion/styled']
  }
})
</file>

<file path="jest.config.js">
module.exports = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  roots: ["<rootDir>/src", "<rootDir>/tests"],
  moduleDirectories: ["node_modules", "src"],
  modulePathIgnorePatterns: ["<rootDir>/dist/"],
  transform: {
    '^.+\\.ts$': 'ts-jest'
  },
  // Look for test files with .test.ts or .spec.ts under the tests folder
  testMatch: ['**/tests/**/*.(test|spec).ts'],
  moduleFileExtensions: ['ts', 'js', 'json', 'node'],
};
</file>

<file path="LICENSE">
Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
</file>

<file path="package.json">
{
  "name": "mcp-code-explainer",
  "version": "1.0.0",
  "type": "module",
  "scripts": {
    "start": "node --loader ts-node/esm src/api.ts",
    "clean": "rimraf dist node_modules",
    "test": "jest",
    "dev": "concurrently \"npm run start\" \"cd frontend && npm run dev\"",
    "frontend": "cd frontend && npm run dev"
  },
  "dependencies": {
    "@types/body-parser": "^1.19.5",
    "@types/cors": "^2.8.17",
    "@types/dotenv": "^6.1.1",
    "body-parser": "^1.20.3",
    "cors": "^2.8.5",
    "dotenv": "^16.4.7",
    "express": "^4.21.2",
    "mermaid": "^11.4.1",
    "mermaid-react": "^0.1.0",
    "ts-morph": "^25.0.1",
    "typescript": "^5.7.3"
  },
  "devDependencies": {
    "@babel/parser": "^7.26.8",
    "@babel/plugin-proposal-class-properties": "^7.18.6",
    "@babel/plugin-transform-class-properties": "^7.25.9",
    "@babel/traverse": "^7.26.8",
    "@babel/types": "^7.26.8",
    "@types/axios": "^0.9.36",
    "@types/express": "^5.0.0",
    "@types/react-icons": "^2.2.7",
    "@types/react-router-dom": "^5.3.3",
    "concurrently": "^8.2.2",
    "rimraf": "^5.0.10",
    "ts-node": "^10.9.2",
    "cursor-tools": "latest"
  }
}
</file>

<file path="README.md">
<!-- Project Overview and instructions -->
</file>

<file path="src/api.ts">
import express, { Request, Response, NextFunction } from 'express';
import bodyParser from 'body-parser';
import { analyzeProject } from './codeAnalyzer/projectAnalyzer.js';
import { generateDoc } from './docGenerator/index.js';
import cors from 'cors';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { ComponentAnalysis } from './mcp/openaiClient';
import dotenv from 'dotenv';
// Load environment variables
dotenv.config();
// Validate OpenAI API key at startup
if (!process.env.OPENAI_API_KEY) {
  console.error('❌ OpenAI API key is missing! Please check your .env file');
  process.exit(1);
}
console.log('✅ OpenAI API key found');
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const app = express();
app.use(cors({ origin: '*' }));
// Refactored custom CORS middleware as an explicit RequestHandler
const customCorsMiddleware: express.RequestHandler = (req, res, next) => {
  res.header('Access-Control-Allow-Origin', '*');
  res.header('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS');
  res.header('Access-Control-Allow-Headers', 'Origin, X-Requested-With, Content-Type, Accept, Authorization');
  if (req.method === 'OPTIONS') {
    res.sendStatus(200);
    return;
  }
  next();
};
app.use(customCorsMiddleware);
app.use(bodyParser.json());
// Serve static files from the public directory
app.use(express.static('public'));
// Debug endpoint to inspect folder resolution details
app.get('/api/debug-folder', (req: Request, res: Response) => {
  const folder = (req.query.folder as string) || "";
  const trimmedFolder = folder.trim();
  // Set BASE_DIR to C: drive root
  const BASE_DIR = 'C:\\';
  // Assemble debug info
  let debugInfo: any = {};
  debugInfo.incomingFolder = trimmedFolder;
  debugInfo.incomingFolderHex = trimmedFolder.split('').map(c => c.charCodeAt(0).toString(16)).join(' ');
  debugInfo.BASE_DIR = BASE_DIR;
  try {
    debugInfo.availableItems = fs.readdirSync(BASE_DIR);
  } catch (e:any) {
    debugInfo.availableItemsError = e.message;
  }
  const resolvedPath = path.resolve(BASE_DIR, trimmedFolder);
  debugInfo.resolvedPath = resolvedPath;
  debugInfo.exists = fs.existsSync(resolvedPath);
  if (fs.existsSync(resolvedPath)) {
    try {
      debugInfo.stats = fs.statSync(resolvedPath);
    } catch (err:any) {
      debugInfo.statsError = err.message;
    }
  }
  res.json(debugInfo);
});
// Helper to wrap async route handlers with error logging
function asyncHandler(fn: (req: Request, res: Response, next: NextFunction) => Promise<any>): express.RequestHandler {
  return (req, res, next) => {
    Promise.resolve(fn(req, res, next)).catch(error => {
      console.error(`Unhandled error in ${req.method} ${req.url}:`, error);
      next(error);
    });
  };
}
app.post('/api/analyze', asyncHandler(async (req: Request, res: Response) => {
  const { folder } = req.body;
  console.log('🔍 DEBUG: Received analyze request');
  console.log('📂 DEBUG: Folder path:', folder);
  if (!folder) {
    console.error('❌ DEBUG: Folder path is missing in the request body.');
    return res.status(400).json({ error: 'Folder path is required' });
  }
  // Use the provided path directly
  const fullPath = path.resolve(folder);
  console.log(`📍 DEBUG: Resolved path: ${fullPath}`);
  // Verify the path exists
  if (!fs.existsSync(fullPath)) {
    console.error(`❌ DEBUG: Folder does not exist: ${fullPath}`);
    return res.status(400).json({ error: 'Folder does not exist' });
  }
  try {
    console.log('🔄 DEBUG: Starting project analysis...');
    // Analyze the project folder
    const analysisResult = await analyzeProject(fullPath);
    console.log(`✅ DEBUG: Analysis complete. Result keys: ${Object.keys(analysisResult).join(', ')}`);
    // Generate comprehensive OpenAI analysis
    console.log('🤖 DEBUG: Starting comprehensive OpenAI analysis...');
    const { analyzeCodebase } = await import('./mcp/openaiClient.js');
    const aiAnalysis = await analyzeCodebase(analysisResult);
    console.log('✨ DEBUG: Successfully received comprehensive OpenAI analysis');
    // Return both the raw code analysis and the structured AI analysis
    return res.status(200).json({
      codeOutput: analysisResult,
      aiAnalysis
    });
  } catch (error) {
    console.error('❌ Error during analysis:', error);
    if (error instanceof Error) {
      console.error('Stack trace:', error.stack);
    }
    return res.status(500).json({ 
      error: 'Analysis failed', 
      details: error instanceof Error ? error.message : 'Unknown error',
      stack: error instanceof Error ? error.stack : undefined
    });
  }
}));
// Error handling middleware for debugging
app.use((err: any, req: Request, res: Response, next: NextFunction) => {
  console.error('Error handling middleware caught error:', err);
  res.status(500).json({ error: err.message, stack: err.stack });
});
// Start the server
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`API server listening on port ${PORT}`);
});
export default app;
</file>

<file path="src/codeAnalyzer/index.ts">
import { logger } from '../utils/logger';
import { AnalysisResult } from "./types";
import { Project, SyntaxKind, Node, SourceFile } from 'ts-morph';
import { FunctionAnalysis, ClassAnalysis } from "./types";
import path from 'path';
/**
 * Analyzes the provided code using ts-morph to extract functions and classes.
 * Expects payload.code to contain a string of TypeScript code.
 *
 * @param payload - Object containing the code and optionally a filePath.
 * @returns AnalysisResult with arrays of functions and classes.
 */
export async function analyzeCode({ code, filePath }: { code: string; filePath: string }): Promise<AnalysisResult> {
    logger.info("\n🔬 Starting detailed code analysis...");
    logger.info(`📂 File: ${filePath}`);
    logger.info(`📊 Code length: ${code.length} characters`);
    logger.info(`📄 First 200 characters of code:\n${code.substring(0, 200)}...`);
    if (!code || !filePath) {
        logger.warn("⚠️ No code or filePath provided. Returning empty analysis result.");
        return { functions: [], classes: [] };
    }
    // Initialize a new ts-morph project
    logger.info("🚀 Initializing ts-morph project...");
    const project = new Project({
        useInMemoryFileSystem: true,
        skipFileDependencyResolution: true,
    });
    // Add the source file to the project
    logger.info("📝 Creating source file...");
    const sourceFile = project.createSourceFile(filePath, code);
    const result: AnalysisResult = {
        functions: [],
        classes: []
    };
    // Analyze functions
    logger.info("\n🔍 Analyzing functions...");
    const functions = sourceFile.getFunctions();
    logger.info(`📊 Found ${functions.length} functions`);
    functions.forEach((func, index) => {
        try {
            logger.info(`\n📋 Processing function ${index + 1}/${functions.length}:`);
            const name = func.getName() || '<anonymous>';
            logger.info(`   Name: ${name}`);
            const parameters = func.getParameters().map(param => {
                const paramName = param.getName();
                const paramType = param.getType().getText();
                logger.info(`   Parameter: ${paramName}: ${paramType}`);
                return {
                    name: paramName,
                    type: paramType
                };
            });
            const returnType = func.getReturnType().getText();
            logger.info(`   Return type: ${returnType}`);
            const body = func.getBody()?.getText() || '';
            logger.info(`   Body length: ${body.length} characters`);
            const docs = func.getJsDocs().map(doc => doc.getText()).join('\n');
            logger.info(`   Documentation: ${docs ? 'Present' : 'None'}`);
            const location = {
                file: path.basename(filePath),
                startLine: func.getStartLineNumber(),
                endLine: func.getEndLineNumber()
            };
            logger.info(`   Location: Lines ${location.startLine}-${location.endLine}`);
            result.functions.push({
                name,
                parameters,
                returnType,
                body,
                documentation: docs,
                location
            });
        } catch (error) {
            logger.error(`❌ Error processing function ${func.getName()}: ${error instanceof Error ? error.message : String(error)}`);
        }
    });
    // Analyze classes
    logger.info("\n🔍 Analyzing classes...");
    const classes = sourceFile.getClasses();
    logger.info(`📊 Found ${classes.length} classes`);
    classes.forEach((cls, index) => {
        try {
            logger.info(`\n📋 Processing class ${index + 1}/${classes.length}:`);
            const name = cls.getName() || '<anonymous>';
            logger.info(`   Name: ${name}`);
            logger.info('   Processing methods...');
            const methods = cls.getMethods().map(method => {
                const methodName = method.getName();
                logger.info(`      Method: ${methodName}`);
                return {
                    name: methodName,
                    parameters: method.getParameters().map(param => {
                        const paramName = param.getName();
                        const paramType = param.getType().getText();
                        logger.info(`         Parameter: ${paramName}: ${paramType}`);
                        return {
                            name: paramName,
                            type: paramType
                        };
                    }),
                    returnType: method.getReturnType().getText(),
                    body: method.getBody()?.getText() || '',
                    documentation: method.getJsDocs().map(doc => doc.getText()).join('\n')
                };
            });
            logger.info('   Processing properties...');
            const properties = cls.getProperties().map(prop => {
                const propName = prop.getName();
                const propType = prop.getType().getText();
                logger.info(`      Property: ${propName}: ${propType}`);
                return {
                    name: propName,
                    type: propType,
                    documentation: prop.getJsDocs().map(doc => doc.getText()).join('\n')
                };
            });
            const docs = cls.getJsDocs().map(doc => doc.getText()).join('\n');
            logger.info(`   Documentation: ${docs ? 'Present' : 'None'}`);
            const location = {
                file: path.basename(filePath),
                startLine: cls.getStartLineNumber(),
                endLine: cls.getEndLineNumber()
            };
            logger.info(`   Location: Lines ${location.startLine}-${location.endLine}`);
            result.classes.push({
                name,
                methods,
                properties,
                documentation: docs,
                location
            });
        } catch (error) {
            logger.error(`❌ Error processing class ${cls.getName()}: ${error instanceof Error ? error.message : String(error)}`);
        }
    });
    logger.info("\n📊 Analysis Summary:");
    logger.info(`   Functions found: ${result.functions.length}`);
    logger.info(`   Classes found: ${result.classes.length}`);
    logger.info("✅ Analysis complete!");
    return result;
}
/**
 * Analyzes the provided code and returns dummy analysis.
 * @param payload - Contains code and filePath.
 * @returns Dummy analysis result.
 */
export async function analyzeCodeDummy(payload: any) {
    logger.info('Analyzing code...');
    // Dummy data: include startLine and endLine for functions and classes.
    return {
        functions: [
            { 
                name: 'exampleFunction', 
                parameters: ['param1'], 
                returnType: 'void',
                filePath: payload.filePath || '',
                startLine: 1,
                endLine: 2
            }
        ],
        classes: [
            { 
                name: 'ExampleClass', 
                methods: ['method1'],
                filePath: payload.filePath || '',
                startLine: 3,
                endLine: 10
            }
        ],
    };
}
</file>

<file path="src/codeAnalyzer/languageParsers/babelParser.ts">
import { parse } from '@babel/parser';
import traverse from '@babel/traverse';
import * as t from '@babel/types';
import fs from 'fs';
import path from 'path';
import { FunctionAnalysis, ClassAnalysis, ILanguageParser } from '../types';
import { logger } from '../../utils/logger';
export class BabelParser implements ILanguageParser {
  canHandle(filePath: string): boolean {
    const canHandle = filePath.endsWith('.js') || filePath.endsWith('.jsx');
    logger.info(`🔍 BabelParser.canHandle check for ${filePath}: ${canHandle}`);
    return canHandle;
  }
  async parseFile(filePath: string): Promise<{
    functions: FunctionAnalysis[];
    classes: ClassAnalysis[];
  }> {
    logger.info('🏁 Starting Babel-based JavaScript analysis...');
    logger.info(`📂 Analyzing file: ${filePath}`);
    try {
      // Read the source file
      logger.info('📖 Reading file contents...');
      const code = fs.readFileSync(filePath, 'utf-8');
      logger.info(`📄 File content length: ${code.length} characters`);
      logger.info(`📄 First 500 characters:\n${code.substring(0, 500)}...`);
      // Parse the code using @babel/parser with enhanced configuration
      logger.info('🔄 Parsing code with Babel...');
      const ast = parse(code, {
        sourceType: 'unambiguous', // Automatically detect module vs. script
        plugins: [
          'jsx',
          'typescript',
          'classProperties',
          'classPrivateProperties',
          'classPrivateMethods',
          'decorators-legacy'
        ],
        errorRecovery: true,
      });
      logger.info('✅ AST generated successfully');
      const functions: FunctionAnalysis[] = [];
      const classes: ClassAnalysis[] = [];
      logger.info('🔄 Starting AST traversal...');
      // Traverse the AST to extract functions and classes
      traverse(ast, {
        FunctionDeclaration(path) {
          logger.info(`📋 Found function declaration: ${path.node.id?.name || 'anonymous'}`);
          const node = path.node;
          if (!node.id) {
            logger.info('⏭️ Skipping anonymous function');
            return;
          }
          const loc = node.loc;
          if (!loc) {
            logger.info('⏭️ Skipping function without location info');
            return;
          }
          logger.info('📝 Processing function parameters...');
          const parameters = node.params.map(param => {
            const paramName = t.isIdentifier(param) ? param.name : 'unknown';
            logger.info(`   Parameter: ${paramName}`);
            return {
              name: paramName,
              type: 'any'
            };
          });
          const functionAnalysis = {
            name: node.id.name,
            type: 'function',
            parameters,
            returnType: 'any',
            location: {
              file: filePath,
              startLine: loc.start.line,
              endLine: loc.end.line
            },
            documentation: extractDocumentation(path),
            codeSnippet: code.slice(loc.start.index, loc.end.index)
          };
          logger.info(`✅ Added function: ${functionAnalysis.name}`);
          functions.push(functionAnalysis);
        },
        ArrowFunctionExpression(path) {
          const node = path.node;
          const parent = path.parent;
          logger.info('📋 Found arrow function expression');
          // Only process arrow functions assigned to variables
          if (t.isVariableDeclarator(parent) && t.isIdentifier(parent.id)) {
            logger.info(`   Name: ${parent.id.name}`);
            const loc = node.loc;
            if (!loc) {
              logger.info('⏭️ Skipping arrow function without location info');
              return;
            }
            logger.info('📝 Processing arrow function parameters...');
            const parameters = node.params.map(param => {
              const paramName = t.isIdentifier(param) ? param.name : 'unknown';
              logger.info(`   Parameter: ${paramName}`);
              return {
                name: paramName,
                type: 'any'
              };
            });
            const functionAnalysis = {
              name: parent.id.name,
              type: 'arrow-function',
              parameters,
              returnType: 'any',
              location: {
                file: filePath,
                startLine: loc.start.line,
                endLine: loc.end.line
              },
              documentation: extractDocumentation(path),
              codeSnippet: code.slice(loc.start.index, loc.end.index)
            };
            logger.info(`✅ Added arrow function: ${functionAnalysis.name}`);
            functions.push(functionAnalysis);
          } else {
            logger.info('⏭️ Skipping non-variable-assigned arrow function');
          }
        },
        ClassDeclaration(path) {
          logger.info('📋 Found class declaration');
          const node = path.node;
          if (!node.id) {
            logger.info('⏭️ Skipping anonymous class');
            return;
          }
          const loc = node.loc;
          if (!loc) {
            logger.info('⏭️ Skipping class without location info');
            return;
          }
          logger.info(`   Class name: ${node.id.name}`);
          logger.info('📝 Processing class methods...');
          // Extract class methods
          const methods = node.body.body
            .filter(member => t.isClassMethod(member))
            .map(member => {
              const method = member as t.ClassMethod;
              const methodLoc = method.loc;
              if (!methodLoc) return null;
              const methodName = t.isIdentifier(method.key) ? method.key.name : 'unknown';
              logger.info(`   Method: ${methodName}`);
              return {
                name: methodName,
                type: method.kind === 'constructor' ? 'constructor' : 'method',
                parameters: method.params.map(param => {
                  const paramName = t.isIdentifier(param) ? param.name : 'unknown';
                  logger.info(`      Parameter: ${paramName}`);
                  return {
                    name: paramName,
                    type: 'any'
                  };
                }),
                returnType: 'any',
                location: {
                  file: filePath,
                  startLine: methodLoc.start.line,
                  endLine: methodLoc.end.line
                },
                documentation: extractDocumentation(path),
                codeSnippet: code.slice(methodLoc.start.index, methodLoc.end.index)
              };
            })
            .filter(method => method !== null) as any[];
          logger.info('📝 Processing class properties...');
          // Extract class properties
          const properties = node.body.body
            .filter(member => t.isClassProperty(member))
            .map(member => {
              const prop = member as t.ClassProperty;
              const propName = t.isIdentifier(prop.key) ? prop.key.name : 'unknown';
              logger.info(`   Property: ${propName}`);
              return {
                name: propName,
                type: prop.typeAnnotation 
                  ? (prop.typeAnnotation as any).typeAnnotation.type.replace('TSType', '') 
                  : 'any',
                documentation: extractDocumentation({ node: prop })
              };
            });
          const classAnalysis = {
            name: node.id.name,
            type: 'class',
            methods,
            properties,
            location: {
              file: filePath,
              startLine: loc.start.line,
              endLine: loc.end.line
            },
            documentation: extractDocumentation(path),
            codeSnippet: code.slice(loc.start.index, loc.end.index)
          };
          logger.info(`✅ Added class: ${classAnalysis.name}`);
          classes.push(classAnalysis);
        }
      });
      logger.info(`✅ Successfully analyzed JavaScript file: ${path.basename(filePath)}`);
      logger.info(`📊 Found ${functions.length} functions and ${classes.length} classes`);
      return { functions, classes };
    } catch (error) {
      logger.error('❌ Error analyzing JavaScript file:', error);
      if (error instanceof Error) {
        logger.error('Stack trace:', error.stack);
        logger.error('Error name:', error.name);
        logger.error('Error message:', error.message);
      }
      throw error;
    }
  }
}
function extractDocumentation(path: any): string {
  const comments = path.node.leadingComments;
  if (!comments || comments.length === 0) {
    logger.info('   No documentation found');
    return '';
  }
  // Get the closest comment block
  const docBlock = comments[comments.length - 1];
  if (docBlock.type !== 'CommentBlock') {
    logger.info('   Documentation is not a block comment');
    return '';
  }
  logger.info('   Found documentation block');
  return docBlock.value.trim();
}
</file>

<file path="src/codeAnalyzer/languageParsers/ILanguageParser.ts">
import { FunctionAnalysis, ClassAnalysis } from '../types';
export interface StructureAnalysis {
  type: string;
  name: string;
  value?: any;
  children?: StructureAnalysis[];
  documentation?: string;
  location: {
    file: string;
    startLine: number;
    endLine: number;
  };
}
export interface ILanguageParser {
  /**
   * Parse a file and return its analysis
   * @param filePath Path to the file to parse
   */
  parseFile(filePath: string): Promise<{
    functions?: FunctionAnalysis[];
    classes?: ClassAnalysis[];
    structure?: StructureAnalysis;
  }>;
  /**
   * Check if this parser can handle the given file
   * @param filePath Path to the file to check
   */
  canHandle(filePath: string): boolean;
}
// Language-specific parser implementations
export class TypeScriptParser implements ILanguageParser {
  canHandle(filePath: string): boolean {
    return filePath.endsWith('.ts') || filePath.endsWith('.tsx');
  }
  async parseFile(filePath: string) {
    const { parseTypeScript } = await import('./tsParser');
    return parseTypeScript(filePath);
  }
}
// Import YAML parser
import { YAMLParser } from './yamlParser';
</file>

<file path="src/codeAnalyzer/languageParsers/ParserRegistry.ts">
import { ILanguageParser } from '../types';
import { TypeScriptParser } from './tsParser';
import { BabelParser } from './babelParser';
import { YAMLParser } from './yamlParser';
export class ParserRegistry {
  private static parsers: ILanguageParser[] = [
    new TypeScriptParser(),
    new BabelParser(),  // Use Babel parser for JavaScript files
    new YAMLParser()
  ];
  static getParserForFile(filePath: string): ILanguageParser | undefined {
    return this.parsers.find(parser => parser.canHandle(filePath));
  }
  static registerParser(parser: ILanguageParser) {
    this.parsers.push(parser);
  }
}
</file>

<file path="src/codeAnalyzer/languageParsers/tsParser.ts">
// src/codeAnalyzer/languageParsers/tsParser.ts
import { Project, SourceFile, Node, SyntaxKind, ts } from 'ts-morph';
import { FunctionAnalysis, ClassAnalysis, Parameter, Location, ILanguageParser } from '../types';
import { logger } from '../../utils/logger';
export class TypeScriptParser implements ILanguageParser {
  canHandle(filePath: string): boolean {
    return filePath.endsWith('.ts') || filePath.endsWith('.tsx');
  }
  async parseFile(filePath: string): Promise<{
    functions: FunctionAnalysis[];
    classes: ClassAnalysis[];
  }> {
    logger.info('🏁 Starting TypeScript analysis...');
    logger.info(`📂 Analyzing file: ${filePath}`);
    try {
      // Initialize ts-morph project
      const project = new Project({
        tsConfigFilePath: 'tsconfig.json',
      });
      // Add the source file to the project
      const sourceFile = project.addSourceFileAtPath(filePath);
      const result = {
        functions: getFunctions(sourceFile),
        classes: getClasses(sourceFile),
      };
      logger.info(`✅ Successfully analyzed TypeScript file: ${filePath}`);
      logger.info(`📊 Found ${result.functions.length} functions and ${result.classes.length} classes`);
      return result;
    } catch (error) {
      logger.error('❌ Error analyzing TypeScript file:', error);
      throw error;
    }
  }
}
function getFunctions(sourceFile: SourceFile): FunctionAnalysis[] {
  const functions: FunctionAnalysis[] = [];
  // Get all function declarations
  sourceFile.getFunctions().forEach(func => {
    const parameters = func.getParameters().map(param => ({
      name: param.getName(),
      type: param.getType().getText(),
    }));
    const returnType = func.getReturnType().getText();
    const body = func.getBody()?.getText() || '';
    const docs = func.getJsDocs().map(doc => doc.getText()).join('\n');
    const location = {
      file: sourceFile.getFilePath(),
      startLine: func.getStartLineNumber(),
      endLine: func.getEndLineNumber(),
    };
    functions.push({
      name: func.getName() || 'anonymous',
      parameters,
      returnType,
      body,
      documentation: docs,
      location,
    });
  });
  // Get all arrow functions
  sourceFile.getDescendantsOfKind(SyntaxKind.ArrowFunction).forEach(arrow => {
    const parameters = arrow.getParameters().map(param => ({
      name: param.getName(),
      type: param.getType().getText(),
    }));
    const returnType = arrow.getReturnType().getText();
    const body = arrow.getBody().getText();
    const docs = arrow.getJsDocs().map(doc => doc.getText()).join('\n');
    const location = {
      file: sourceFile.getFilePath(),
      startLine: arrow.getStartLineNumber(),
      endLine: arrow.getEndLineNumber(),
    };
    // Only include named arrow functions
    const parent = arrow.getParent();
    if (Node.isVariableDeclaration(parent)) {
      functions.push({
        name: parent.getName(),
        parameters,
        returnType,
        body,
        documentation: docs,
        location,
      });
    }
  });
  return functions;
}
function getClasses(sourceFile: SourceFile): ClassAnalysis[] {
  const classes: ClassAnalysis[] = [];
  sourceFile.getClasses().forEach(cls => {
    const methods = cls.getMethods().map(method => ({
      name: method.getName(),
      parameters: method.getParameters().map(param => ({
        name: param.getName(),
        type: param.getType().getText(),
      })),
      returnType: method.getReturnType().getText(),
      body: method.getBody()?.getText() || '',
      documentation: method.getJsDocs().map(doc => doc.getText()).join('\n'),
    }));
    const properties = cls.getProperties().map(prop => ({
      name: prop.getName(),
      type: prop.getType().getText(),
      documentation: prop.getJsDocs().map(doc => doc.getText()).join('\n'),
    }));
    const docs = cls.getJsDocs().map(doc => doc.getText()).join('\n');
    const location = {
      file: sourceFile.getFilePath(),
      startLine: cls.getStartLineNumber(),
      endLine: cls.getEndLineNumber(),
    };
    const className = cls.getName();
    if (className) {
      classes.push({
        name: className,
        methods,
        properties,
        documentation: docs,
        location,
      });
    }
  });
  return classes;
}
</file>

<file path="src/codeAnalyzer/languageParsers/yamlParser.ts">
import yaml from 'js-yaml';
import * as fs from 'fs';
import { ILanguageParser, FunctionAnalysis, ClassAnalysis } from '../types';
export class YAMLParser implements ILanguageParser {
  canHandle(filePath: string): boolean {
    return filePath.endsWith('.yml') || filePath.endsWith('.yaml');
  }
  async parseFile(filePath: string): Promise<{
    functions?: FunctionAnalysis[];
    classes?: ClassAnalysis[];
  }> {
    const content = fs.readFileSync(filePath, 'utf8');
    const document = yaml.load(content) as any;
    // YAML files don't contain functions or classes in the traditional sense
    // Return empty arrays to match the interface
    return {
      functions: [],
      classes: []
    };
  }
}
</file>

<file path="src/codeAnalyzer/projectAnalyzer.ts">
import fs from 'fs';
import path from 'path';
import { analyzeCode } from './index';
import { readFile } from '../utils/fileUtils';
import { AnalysisResult } from './types';
import { logger } from '../utils/logger';
import { ParserRegistry } from './languageParsers/ParserRegistry';
/**
 * Recursively lists all files in a given directory.
 * @param dirPath - The directory path to search.
 * @returns An array of file paths.
 */
function listFilesRecursively(dirPath: string): string[] {
  let results: string[] = [];
  const IGNORED_DIRS = new Set(["node_modules", ".git", "dist", ".idea", ".vscode"]);
  logger.info(`🔍 Scanning directory: ${dirPath}`);
  const list = fs.readdirSync(dirPath);
  list.forEach(file => {
    if (IGNORED_DIRS.has(file)) {
      logger.info(`⏭️ Skipping ignored directory: ${file}`);
      return;
    }
    const filePath = path.join(dirPath, file);
    const stat = fs.statSync(filePath);
    if (stat && stat.isDirectory()) {
      logger.info(`📁 Found directory: ${file}`);
      results = results.concat(listFilesRecursively(filePath));
    } else {
      logger.info(`📄 Found file: ${file}`);
      results.push(filePath);
    }
  });
  return results;
}
/**
 * Analyzes an entire project by scanning the given directory recursively.
 * It reads all .ts and .js files and aggregates their analysis results.
 * 
 * @param folder - The root directory of the project.
 * @returns Aggregated analysis result including functions and classes.
 */
export async function analyzeProject(folder: string): Promise<AnalysisResult> {
  // Trim any extra whitespace from the folder string
  folder = folder.trim();
  logger.info('🚀 Starting project analysis...');
  logger.info('📂 Input folder:', folder);
  logger.info('📂 Folder string hex:', folder.split('').map(c => c.charCodeAt(0).toString(16)).join(' '));
  // Use the provided path directly since it should be absolute
  const resolvedPath = path.normalize(folder);
  logger.info('📂 Resolved path:', resolvedPath);
  // Verify that the folder exists before proceeding
  if (!fs.existsSync(resolvedPath)) {
    logger.error(`❌ Folder does not exist: ${resolvedPath}`);
    throw new Error(`Folder does not exist: ${resolvedPath}`);
  }
  // Use the resolved path for scanning files
  const files = listFilesRecursively(resolvedPath);
  logger.info(`📊 Total files found: ${files.length}`);
  const analysisResult: AnalysisResult = { functions: [], classes: [] };
  // Filter for JavaScript and TypeScript files.
  const codeFiles = files.filter(file => file.endsWith('.ts') || file.endsWith('.js'));
  logger.info(`📊 Code files to analyze: ${codeFiles.length}`);
  logger.info('📄 Code files:', codeFiles);
  for (const file of codeFiles) {
    try {
      logger.info(`\n🔍 Analyzing file: ${file}`);
      logger.info(`📂 File extension: ${path.extname(file)}`);
      // Get appropriate parser
      const parser = ParserRegistry.getParserForFile(file);
      logger.info(`🔧 Selected parser: ${parser?.constructor.name || 'None'}`);
      if (!parser) {
        logger.warn(`⚠️ No parser found for file: ${file}`);
        continue;
      }
      logger.info('📖 Reading file contents...');
      const code = readFile(file);
      logger.info(`📄 File content length: ${code.length} characters`);
      logger.info(`📄 First 500 characters:\n${code.substring(0, 500)}...`);
      logger.info('🔄 Starting parser execution...');
      const result = await parser.parseFile(file);
      logger.info(`✅ Parser execution complete for ${file}:`);
      logger.info(`📊 Functions found: ${result.functions?.length || 0}`);
      logger.info(`📊 Classes found: ${result.classes?.length || 0}`);
      // Log detailed function info
      result.functions?.forEach((func, index) => {
        logger.info(`\n📋 Function ${index + 1}:`);
        logger.info(`   Name: ${func.name}`);
        logger.info(`   Parameters: ${JSON.stringify(func.parameters)}`);
        logger.info(`   Return type: ${func.returnType}`);
        logger.info(`   Location: ${JSON.stringify(func.location)}`);
      });
      // Log detailed class info
      result.classes?.forEach((cls, index) => {
        logger.info(`\n📋 Class ${index + 1}:`);
        logger.info(`   Name: ${cls.name}`);
        logger.info(`   Methods: ${cls.methods.length}`);
        logger.info(`   Properties: ${cls.properties.length}`);
        logger.info(`   Location: ${JSON.stringify(cls.location)}`);
      });
      if (result.functions) analysisResult.functions.push(...result.functions);
      if (result.classes) analysisResult.classes.push(...result.classes);
    } catch (err) {
      // Enhanced error logging
      logger.error(`❌ Error analyzing file ${file}:`, err);
      if (err instanceof Error) {
        logger.error('Stack trace:', err.stack);
        logger.error('Error name:', err.name);
        logger.error('Error message:', err.message);
      }
      // Continue with other files
    }
  }
  logger.info('\n📊 Final Analysis Summary:');
  logger.info(`📊 Total functions found: ${analysisResult.functions.length}`);
  logger.info(`📊 Total classes found: ${analysisResult.classes.length}`);
  // Log the complete analysis result
  logger.info('\n📋 Complete Analysis Result:');
  logger.info(JSON.stringify(analysisResult, null, 2));
  return analysisResult;
}
</file>

<file path="src/codeAnalyzer/types.ts">
// src/codeAnalyzer/types.ts
// Define interfaces for code analysis results
export interface FunctionInfo {
    name: string;
    parameters: string[];
    returnType: string;
}
export interface ClassInfo {
    name: string;
    methods: string[];
}
export interface Parameter {
    name: string;
    type: string;
}
export interface Location {
    file: string;
    startLine: number;
    endLine: number;
}
export interface FunctionAnalysis {
    name: string;
    type?: string;  // Added for Babel parser
    parameters: Parameter[];
    returnType: string;
    body?: string;  // Made optional since we use codeSnippet
    codeSnippet?: string;  // Added for Babel parser
    documentation: string;
    location: Location;
}
export interface ClassProperty {
    name: string;
    type: string;
    documentation: string;
}
export interface ClassMethod {
    name: string;
    type?: string;  // Added for Babel parser
    parameters: Parameter[];
    returnType: string;
    body?: string;  // Made optional since we use codeSnippet
    codeSnippet?: string;  // Added for Babel parser
    documentation: string;
    location?: Location;  // Added for Babel parser
}
export interface ClassAnalysis {
    name: string;
    type?: string;  // Added for Babel parser
    methods: ClassMethod[];
    properties: ClassProperty[];
    documentation: string;
    location: Location;
    codeSnippet?: string;  // Added for Babel parser
}
export interface AnalysisResult {
    functions: FunctionAnalysis[];
    classes: ClassAnalysis[];
}
// Language Parser Interface
export interface ILanguageParser {
    /**
     * Parse a file and return its analysis.
     * @param filePath Path to the file to parse.
     */
    parseFile(filePath: string): Promise<{
        functions?: FunctionAnalysis[];
        classes?: ClassAnalysis[];
    }>;
    /**
     * Check if this parser can handle the given file.
     * @param filePath Path to the file to check.
     */
    canHandle(filePath: string): boolean;
}
</file>

<file path="src/config/config.ts">
import fs from 'fs';
import path from 'path';
export interface Config {
    supportedLanguages: string[];
    defaultTemplatePath: string;
    mcpPort: number; // For future use if integrating a network-based server.
}
// Default configuration values.
const defaultConfig: Config = {
    supportedLanguages: ['typescript', 'javascript'],
    defaultTemplatePath: path.join(__dirname, '..', 'templates', 'default.hbs'),
    mcpPort: 3000,
};
/**
 * Retrieves the configuration.
 * In the future, this could be extended to read from a JSON file or environment variables.
 *
 * @returns Config object.
 */
export function getConfig(): Config {
    // For now, simply return the default configuration.
    // Optionally, check if a config file exists and merge with defaultConfig.
    return defaultConfig;
}
</file>

<file path="src/docGenerator.ts">
// Module to generate documentation from parsed data 
// src/docGenerator.ts
import fs from 'fs';
import path from 'path';
import Handlebars from 'handlebars';
import { logger } from './utils/logger';
export async function generateDocumentation(payload: any): Promise<string> {
  // Payload may include analysis result and template choice
  logger.info('Generating documentation...');
  // Load the template (using default.hbs in the templates directory)
  const templatePath = path.join(__dirname, '..', 'templates', 'default.hbs');
  const templateContent = fs.readFileSync(templatePath, 'utf-8');
  const template = Handlebars.compile(templateContent);
  // Render the documentation using the analysis data provided in payload
  const documentation = template(payload);
  return documentation;
}
</file>

<file path="src/docGenerator/helpers.ts">
// src/docGenerator/helpers.ts
// Register Handlebars helpers if necessary
import Handlebars from "handlebars";
/**
 * Registers custom Handlebars helpers.
 * This is a stub implementation. Add actual helper functions as needed.
 */
export function registerHelpers() {
  // Example custom helper (currently commented out)
  // Handlebars.registerHelper('uppercase', function (str) {
  //   return str.toUpperCase();
  // });
  // No custom helpers defined yet.
}
</file>

<file path="src/docGenerator/index.ts">
console.log("generateDocumentation module loaded!");
import { logger } from "../utils/logger";
import { compileTemplate } from './templateEngine';
/**
 * Generates documentation based on the payload.
 * For now, it returns dummy documentation.
 *
 * @param payload - Contains parameters needed for documentation generation.
 * @returns Object with generated documentation.
 */
export async function generateDocumentation(payload: any): Promise<{ docs: string }> {
    logger.info("Generating documentation...");
    return { docs: "dummy documentation" };
}
export function generateDoc(analysisData: any): string {
  // For simplicity, we assume that analysisData matches the expected template context.
  return compileTemplate(analysisData);
}
</file>

<file path="src/docGenerator/templateEngine.ts">
import fs from "fs";
import path from "path";
import Handlebars from "handlebars";
import { registerHelpers } from "./helpers";
// Register any custom helpers
registerHelpers();
// Register a helper to wrap code in triple backticks for proper markdown formatting
Handlebars.registerHelper("codeBlock", function(code: string, language: string = "javascript") {
  if (!code) return "";
  return new Handlebars.SafeString("```" + language + "\n" + code + "\n```");
});
/**
 * Renders a Handlebars template with the provided data.
 *
 * @param template - The template string to render.
 * @param data - The data to inject into the template.
 * @returns The rendered template string.
 */
export function renderTemplate(template: string, data: any): string {
    const compiledTemplate = Handlebars.compile(template);
    return compiledTemplate(data);
}
export function templateEngine(payload: any): string {
  // Load the default Handlebars template from the templates folder
  const templatePath = path.join(__dirname, "..", "templates", "default.hbs");
  const templateContent = fs.readFileSync(templatePath, "utf-8");
  // Compile the template
  const template = Handlebars.compile(templateContent);
  // Render the documentation using the provided payload (analysis results, etc.)
  return template(payload);
}
// New function to compile the default template with a provided context
export function compileTemplate(context: any): string {
  const templatePath = path.join(__dirname, '../../templates/default.hbs');
  const templateContent = fs.readFileSync(templatePath, 'utf-8');
  const template = Handlebars.compile(templateContent);
  return template(context);
}
</file>

<file path="src/index.ts">
// Entry point for MCP server integration 
// src/index.ts
import { createInterface } from 'readline';
import { v4 as uuidv4 } from 'uuid';
import { handleMCPRequest } from './mcpHandler';
import { logger } from './utils/logger';
// Set up a basic interface to read from stdio for MCP messages
const rl = createInterface({
  input: process.stdin,
  output: process.stdout,
  terminal: false,
});
logger.info('MCP Server starting...');
rl.on('line', async (line: string) => {
  if (!line.trim()) return;
  const requestId = uuidv4();
  logger.info(`[${requestId}] Received message: ${line}`);
  try {
    const request = JSON.parse(line);
    const response = await handleMCPRequest(request);
    process.stdout.write(JSON.stringify(response) + '\n');
    logger.info(`[${requestId}] Processed successfully`);
  } catch (error) {
    logger.error(`[${requestId}] Failed to process MCP message`, error);
    process.stdout.write(
      JSON.stringify({ error: 'Invalid request format' }) + '\n'
    );
  }
});
</file>

<file path="src/mcp/integration.ts">
import { analyzeCode } from '../codeAnalyzer';
import { generateDocumentation } from '../docGenerator';
import { logger } from '../utils/logger';
import { sendQuery } from './openaiClient';
/**
 * Aggregates context from internal modules and sends it to an LLM via OpenAI.
 * @param payload - Input payload from the MCP command.
 * @returns Response from OpenAI as a standardized MCP output.
 */
export async function assist(payload: any): Promise<any> {
  logger.info("Aggregating context for 'assist' command");
  // Aggregate data from internal modules.
  let analysisResult;
  let documentationResult;
  // Use existing analysis if present, otherwise attempt to analyze the code.
  try {
    if (payload && (payload.functions || payload.classes)) {
      analysisResult = payload; // Payload already has analysis data.
      logger.info("Using existing analysis data from payload.");
    } else if (payload && payload.code) {
      analysisResult = await analyzeCode(payload);
    } else {
      logger.info("Payload lacks expected analysis data; defaulting to empty analysis result.");
      analysisResult = { functions: [], classes: [] };
    }
  } catch (err) {
    logger.error("Error in analyzeCode:", err);
    analysisResult = { error: "analysis failed" };
  }
  try {
    documentationResult = await generateDocumentation(payload);
  } catch (err) {
    logger.error("Error in generateDocumentation:", err);
    documentationResult = { error: "documentation generation failed" };
  }
  // Build a unified context object.
  const context = {
    analysis: analysisResult,
    documentation: documentationResult,
    // Extend with additional context as needed (e.g., project metadata)
  };
  // Prepare a query for the LLM using our OpenAI integration.
  try {
    const langChainResponse = await sendQuery({
      prompt: "Convert the following technical analysis and generated documentation into a human-friendly summary. Please explain in clear, plain language what the project does, detail the purpose of each primary module, and highlight key insights relevant to developers.",
      context: context,
    });
    return { assistantResponse: langChainResponse };
  } catch (error) {
    logger.error("Error during OpenAI integration", error);
    throw new Error("OpenAI API call failed");
  }
}
</file>

<file path="src/mcp/openaiClient.ts">
import { OpenAI } from "openai";
import { logger } from "../utils/logger";
import dotenv from 'dotenv';
import path from 'path';
// Load environment variables
dotenv.config();
// Check for API key
const apiKey = process.env.OPENAI_API_KEY;
if (!apiKey) {
  logger.error("❌ OpenAI API key is missing! Please check your .env file");
  throw new Error("OpenAI API key is required");
}
logger.info("✅ OpenAI API key found");
// Initialize the OpenAI client with the API key from environment
const openai = new OpenAI({
  apiKey
});
export interface ComponentAnalysis {
  type: 'class' | 'function' | 'component';
  name: string;
  description: string;
  implementation: string;
  usage: string;
  bestPractices?: string[];
  parameters?: {
    name: string;
    type: string;
    description: string;
  }[];
  returns?: {
    type: string;
    description: string;
  };
  relationships?: {
    dependencies: {
      name: string;
      type: 'import' | 'function_call' | 'inheritance' | 'composition' | 'event_handler' | 'class' | 'component';
      description: string;
    }[];
    dependents?: {
      name: string;
      type: 'import' | 'function_call' | 'inheritance' | 'composition' | 'event_handler' | 'class' | 'component';
      description: string;
    }[];
    dataFlow?: {
      direction: 'in' | 'out' | 'bidirectional';
      component: string;
      description: string;
    }[];
  };
}
export interface SystemOverview {
  description: string;
  architecture: string;
  mainComponents: string[];
  dataFlow: string;
  technicalStack: string[];
}
export interface SecurityAnalysis {
  securityRisks: Array<{
    risk: string;
    severity: 'low' | 'medium' | 'high';
    mitigation: string;
  }>;
  bestPractices: string[];
  recommendations: string[];
}
export interface DependencyGraph {
  nodes: Array<{
    id: string;
    type: 'function' | 'class' | 'component' | 'module';
    description: string;
  }>;
  edges: Array<{
    from: string;
    to: string;
    type: string;
    description: string;
  }>;
}
export interface PerformanceAnalysis {
  complexityAnalysis: Array<{
    component: string;
    cyclomaticComplexity: number;
    recommendations: string[];
    hotspots: string[];
  }>;
  memoryUsage: Array<{
    component: string;
    concerns: string[];
    optimizations: string[];
  }>;
  asyncPatterns: Array<{
    component: string;
    pattern: string;
    risks: string[];
    improvements: string[];
  }>;
}
export interface TestabilityAnalysis {
  untested: string[];
  testRecommendations: Array<{
    component: string;
    testTypes: string[];
    testCases: string[];
    mocking: string[];
  }>;
  coverage: {
    current: string;
    recommendations: string[];
  };
}
export interface CodeQualityAnalysis {
  maintainability: Array<{
    component: string;
    score: number;
    issues: string[];
    improvements: string[];
  }>;
  duplication: Array<{
    pattern: string;
    locations: string[];
    refactoringStrategy: string;
  }>;
  naming: Array<{
    component: string;
    issues: string[];
    suggestions: string[];
  }>;
}
// Helper to validate response structure
function validateResponseStructure(response: any, responseFormat?: any): boolean {
  if (!response || typeof response !== 'object') {
    logger.error("❌ Response is not an object:", response);
    return false;
  }
  // If a specific response format is provided, just verify it's an object
  if (responseFormat) {
    return true;
  }
  // Check for either a direct components array or a nested analysis structure
  if (response.components && Array.isArray(response.components)) {
    // Validate each component
    for (const component of response.components) {
      if (!validateComponent(component)) {
        return false;
      }
    }
    return true;
  }
  // Check for nested analysis structure
  if (response.analysis && typeof response.analysis === 'object') {
    const { functions, classes, modules } = response.analysis;
    let hasValidContent = false;
    // Validate functions array if present
    if (functions) {
      if (!Array.isArray(functions)) {
        logger.error("❌ Functions is not an array:", functions);
        return false;
      }
      for (const func of functions) {
        if (!validateFunction(func)) {
          return false;
        }
      }
      if (functions.length > 0) hasValidContent = true;
    }
    // Validate classes array if present
    if (classes) {
      if (!Array.isArray(classes)) {
        logger.error("❌ Classes is not an array:", classes);
        return false;
      }
      for (const cls of classes) {
        if (!validateClass(cls)) {
          return false;
        }
      }
      if (classes.length > 0) hasValidContent = true;
    }
    // Validate modules array if present
    if (modules) {
      if (!Array.isArray(modules)) {
        logger.error("❌ Modules is not an array:", modules);
        return false;
      }
      for (const module of modules) {
        if (!validateModule(module)) {
          return false;
        }
      }
      if (modules.length > 0) hasValidContent = true;
    }
    // At least one array should be present and have content
    if (hasValidContent) {
      return true;
    }
    logger.error("❌ Analysis object has no valid content arrays");
    return false;
  }
  logger.error("❌ Response does not contain a valid structure. Expected either components array or analysis object with functions/classes/modules arrays:", response);
  return false;
}
// Update the system prompt in the sendQuery function
const systemPrompt = `You are a highly skilled documentation assistant that analyzes code and provides structured JSON output. Your responses must ALWAYS be valid JSON matching the specified schema exactly, with no extraneous text before or after. Use complete and runnable code snippets when available.
Expected Response Format:
{
  "analysis": {
    "functions": [...],  // Array of function analyses
    "classes": [...],    // Array of class analyses
    "modules": [...]     // Array of module analyses
  }
}
Key Guidelines for All Analyses:
1. Code Integrity: Never split code examples mid-block.
2. Complete Usage: Each usage example should be self-contained and runnable.
3. Contextual Code: Include actual code snippets from the context where relevant.
4. Clarity & Precision: Keep descriptions clear, concise, and actionable.
5. Type-Specific Analysis:
   - Functions: Identify called functions and those that call them.
   - Classes: Document inheritance, composition, and method interactions.
   - Modules: List all imports/exports and their usage patterns.
6. Relationship Mapping:
   - Detail function calls, class inheritance/composition, module dependencies, event handling, and data flow between components.`;
/**
 * Sends a query to the OpenAI API using the ChatCompletion endpoint.
 *
 * @param query An object containing a "prompt" and a "context" that will be fed to the LLM.
 * @returns The assistant's response as a ComponentAnalysis[].
 */
export async function sendQuery(query: { 
  prompt: string; 
  context: any;
  responseFormat?: any;  // Optional JSON schema for the response
}): Promise<any> {
  const { prompt, context, responseFormat } = query;
  logger.info("🚀 Starting OpenAI query...");
  // Prepare the context text (JSON-stringified).
  const contextText = (() => {
    // Deep clone the context to avoid modifying the original
    const optimizedContext = JSON.parse(JSON.stringify(context));
    // Helper to optimize code content
    const optimizeCode = (code: string) => {
      if (!code) return '';
      return code
        .replace(/\/\*[\s\S]*?\*\//g, '') // Remove multi-line comments
        .replace(/\/\/.*/g, '') // Remove single-line comments
        .replace(/console\.(log|warn|error|info|debug)\([^)]*\);?/g, '') // Remove all console statements
        .replace(/\s+/g, ' ') // Normalize whitespace
        .trim();
    };
    // Helper to extract essential info from a function/method body
    const extractEssentialCode = (body: string) => {
      const cleanBody = optimizeCode(body);
      // Keep function signature and structure, remove implementation details if too long
      if (cleanBody.length > 500) {
        const lines = cleanBody.split('\n');
        const firstLines = lines.slice(0, 3).join('\n'); // Keep first 3 lines
        const lastLines = lines.slice(-2).join('\n');    // Keep last 2 lines
        return `${firstLines}\n  // ... implementation ...\n${lastLines}`;
      }
      return cleanBody;
    };
    // Optimize functions
    if (optimizedContext.functions) {
      optimizedContext.functions = optimizedContext.functions.map((func: any) => ({
        name: func.name,
        parameters: func.parameters,
        returnType: func.returnType,
        body: extractEssentialCode(func.body || ''),
        documentation: func.documentation,
        location: func.location ? {
          file: path.basename(func.location.file),
          startLine: func.location.startLine,
          endLine: func.location.endLine
        } : undefined
      }));
    }
    // Optimize classes
    if (optimizedContext.classes) {
      optimizedContext.classes = optimizedContext.classes.map((cls: any) => ({
        name: cls.name,
        methods: cls.methods?.map((method: any) => ({
          name: method.name,
          parameters: method.parameters,
          returnType: method.returnType,
          body: extractEssentialCode(method.body || ''),
          documentation: method.documentation
        })),
        properties: cls.properties,
        documentation: cls.documentation,
        location: cls.location ? {
          file: path.basename(cls.location.file),
          startLine: cls.location.startLine,
          endLine: cls.location.endLine
        } : undefined
      }));
    }
    // Add optimization metadata
    optimizedContext._meta = {
      optimized: true,
      timestamp: new Date().toISOString(),
      note: 'Code bodies have been optimized for token efficiency while preserving essential structure'
    };
    return JSON.stringify(optimizedContext, null, 2);
  })();
  if (!contextText.trim()) {
    logger.error("❌ No code provided in payload.");
    throw new Error("No code provided in payload");
  }
  logger.info(`📦 Context size: ${contextText.length} characters`);
  logger.info(`📝 Prompt: ${prompt}`);
  // Compose the full user message.
  const fullUserContent = `${prompt}\n\nContext:\n${contextText}\n\n${systemPrompt}`;
  try {
    logger.info("📡 Making OpenAI API call...");
    const completion = await openai.chat.completions.create({
      model: "chatgpt-4o-latest",
      messages: [
        { 
          role: "system", 
          content: systemPrompt
        },
        { role: "user", content: fullUserContent }
      ],
      temperature: 0.3,
      response_format: { type: "json_object" },
      seed: 123,
      max_tokens: 16000
    });
    const response = completion.choices[0].message?.content;
    if (!response) {
      logger.error("❌ No response content received from OpenAI");
      throw new Error("No response received from OpenAI");
    }
    logger.info("✅ Received response from OpenAI");
    logger.info("📝 Raw response:", response);
    try {
      // Remove any potential non-JSON text before the first {
      const jsonStart = response.indexOf('{');
      const jsonEnd = response.lastIndexOf('}') + 1;
      const jsonStr = response.slice(jsonStart, jsonEnd);
      logger.info("🔄 Attempting to parse response as JSON...");
      const parsedResponse = JSON.parse(jsonStr);
      logger.info("✅ Successfully parsed JSON. Structure:", JSON.stringify(parsedResponse, null, 2));
      logger.info("🔍 Validating response structure...");
      if (!validateResponseStructure(parsedResponse, responseFormat)) {
        throw new Error("Invalid response structure");
      }
      // If using responseFormat, return the whole response
      if (responseFormat) {
        return parsedResponse;
      }
      // Return either analysis or components array
      return parsedResponse.analysis || parsedResponse.components;
    } catch (error: unknown) {
      if (error instanceof Error) {
        logger.error("❌ Parse error details:", error.message);
      } else {
        logger.error("❌ Unknown parse error:", error);
      }
      logger.error("❌ Failed response content:", response);
      throw new Error(`Failed to parse OpenAI response as JSON: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  } catch (error) {
    logger.error("❌ OpenAI API error details:", error);
    throw error;
  }
}
// Helper to chunk large codebases
function chunkCodebase(context: any, maxChunkSize: number = 32000): any[] {
  logger.info("🔄 Starting codebase chunking...");
  logger.info(`📊 Max chunk size: ${maxChunkSize} tokens (approx)`);
  const chunks: any[] = [];
  // Helper to estimate tokens (rough approximation: 1 token ≈ 4 chars)
  const estimateTokens = (str: string): number => Math.ceil(str.length / 4);
  // If context has functions array, chunk it
  if (context.functions && Array.isArray(context.functions)) {
    const functionChunks: any[][] = [];
    let currentChunk: any[] = [];
    let currentSize = 0;
    for (const func of context.functions) {
      const funcStr = JSON.stringify(func);
      const funcTokens = estimateTokens(funcStr);
      logger.info(`📏 Function "${func.name}" estimated tokens: ${funcTokens}`);
      // If a single function is too large, we need to handle it specially
      if (funcTokens > maxChunkSize) {
        logger.warn(`⚠️ Large function detected: "${func.name}" (${funcTokens} tokens)`);
        // Try to break it down by removing the body if it's too large
        const funcWithoutBody = { ...func, body: "/* Body too large, truncated */" };
        const reducedTokens = estimateTokens(JSON.stringify(funcWithoutBody));
        logger.info(`📉 Reduced to ${reducedTokens} tokens`);
        currentChunk.push(funcWithoutBody);
        continue;
      }
      if (currentSize + funcTokens > maxChunkSize && currentChunk.length > 0) {
        logger.info(`📦 Creating new chunk with ${currentChunk.length} functions (${currentSize} tokens)`);
        functionChunks.push([...currentChunk]);
        currentChunk = [];
        currentSize = 0;
      }
      currentChunk.push(func);
      currentSize += funcTokens;
    }
    if (currentChunk.length > 0) {
      logger.info(`📦 Adding final function chunk with ${currentChunk.length} functions (${currentSize} tokens)`);
      functionChunks.push(currentChunk);
    }
    chunks.push(...functionChunks.map(funcs => ({ ...context, functions: funcs })));
  }
  // Similarly chunk classes if present
  if (context.classes && Array.isArray(context.classes)) {
    const classChunks: any[][] = [];
    let currentChunk: any[] = [];
    let currentSize = 0;
    for (const cls of context.classes) {
      const clsStr = JSON.stringify(cls);
      const clsTokens = estimateTokens(clsStr);
      logger.info(`📏 Class "${cls.name}" estimated tokens: ${clsTokens}`);
      // Handle large classes
      if (clsTokens > maxChunkSize) {
        logger.warn(`⚠️ Large class detected: "${cls.name}" (${clsTokens} tokens)`);
        // Try to break it down by methods if possible
        const methodChunks: any[] = [];
        let currentMethods: any[] = [];
        let methodSize = 0;
        for (const method of cls.methods || []) {
          const methodTokens = estimateTokens(JSON.stringify(method));
          if (methodSize + methodTokens > maxChunkSize) {
            methodChunks.push([...currentMethods]);
            currentMethods = [];
            methodSize = 0;
          }
          currentMethods.push(method);
          methodSize += methodTokens;
        }
        if (currentMethods.length > 0) {
          methodChunks.push(currentMethods);
        }
        // Create separate chunks for each method group
        methodChunks.forEach((methods, idx) => {
          const partialClass = {
            ...cls,
            methods,
            note: `Part ${idx + 1}/${methodChunks.length} of large class`
          };
          currentChunk.push(partialClass);
        });
        continue;
      }
      if (currentSize + clsTokens > maxChunkSize && currentChunk.length > 0) {
        logger.info(`📦 Creating new chunk with ${currentChunk.length} classes (${currentSize} tokens)`);
        classChunks.push([...currentChunk]);
        currentChunk = [];
        currentSize = 0;
      }
      currentChunk.push(cls);
      currentSize += clsTokens;
    }
    if (currentChunk.length > 0) {
      logger.info(`📦 Adding final class chunk with ${currentChunk.length} classes (${currentSize} tokens)`);
      classChunks.push(currentChunk);
    }
    chunks.push(...classChunks.map(classes => ({ ...context, classes })));
  }
  logger.info(`✅ Chunking complete. Created ${chunks.length} chunks`);
  chunks.forEach((chunk, i) => {
    const size = estimateTokens(JSON.stringify(chunk));
    logger.info(`   Chunk ${i + 1}: ~${size} tokens`);
  });
  return chunks.length > 0 ? chunks : [context];
}
/**
 * Analyzes a large codebase by breaking it into chunks and making multiple API calls.
 */
export async function analyzeChunkedCodebase(context: any): Promise<{
  overview: SystemOverview;
  components: ComponentAnalysis[];
  dependencies: DependencyGraph;
}> {
  logger.info("🚀 Starting chunked codebase analysis...");
  // First get the overview since it needs the full context
  logger.info("📊 Getting system overview...");
  const overview = await sendQuery({ 
    prompt: "Analyze the entire codebase and deliver a concise yet comprehensive system overview. Focus on the overall architecture, primary components, data flow patterns, and the technical stack in use. Your analysis should provide high-level insights along with concrete details from the code.",
    context,
    responseFormat: {
      type: "object",
      properties: {
        description: { 
          type: "string",
          description: "Brief summary of the system's functionality and purpose"
        },
        architecture: { 
          type: "string",
          description: "Description of the architectural style and design patterns (e.g., microservices, MVC)"
        },
        mainComponents: { 
          type: "array", 
          items: { type: "string" },
          description: "List of key modules or components"
        },
        dataFlow: { 
          type: "string",
          description: "Explanation of how data moves between the components"
        },
        technicalStack: { 
          type: "array", 
          items: { type: "string" },
          description: "List of languages, frameworks, libraries, and tools used"
        }
      }
    }
  });
  // Chunk the codebase for detailed analysis
  const chunks = chunkCodebase(context);
  logger.info(`🔄 Split codebase into ${chunks.length} chunks for analysis`);
  // Analyze each chunk
  const componentAnalyses: ComponentAnalysis[][] = [];
  for (let i = 0; i < chunks.length; i++) {
    logger.info(`📝 Analyzing chunk ${i + 1}/${chunks.length}...`);
    const chunkAnalysis = await sendQuery({ 
      prompt: "Perform an in-depth, component-level analysis of the provided code. For each function, class, or module, include detailed explanations, actual code snippets, usage examples, and best practices. Highlight parameters, return types, and explicit relationships with other components.", 
      context: chunks[i] 
    });
    componentAnalyses.push(chunkAnalysis);
  }
  // Flatten component analyses
  const components = componentAnalyses.flat();
  // Get dependency graph (can use full context as it's relationship-focused)
  logger.info("🕸️ Generating dependency graph...");
  const dependencies = await sendQuery({ 
    prompt: "Generate a complete dependency graph of the codebase. Map every relationship between functions, classes, components, and modules. Include details on imports, function calls, inheritance, composition, event handling, and data flow interactions.", 
    context,
    responseFormat: {
      type: "object",
      properties: {
        nodes: {
          type: "array",
          items: {
            type: "object",
            properties: {
              id: { 
                type: "string",
                description: "UniqueIdentifier"
              },
              type: { 
                type: "string", 
                enum: ["function", "class", "component", "module"],
                description: "Type of the component"
              },
              description: { 
                type: "string",
                description: "Brief description of the component"
              }
            }
          }
        },
        edges: {
          type: "array",
          items: {
            type: "object",
            properties: {
              from: { 
                type: "string",
                description: "SourceComponentIdentifier"
              },
              to: { 
                type: "string",
                description: "TargetComponentIdentifier"
              },
              type: { 
                type: "string",
                description: "RelationshipType (e.g., function_call, inheritance)"
              },
              description: { 
                type: "string",
                description: "Explanation of how the two components interact"
              }
            }
          }
        }
      }
    }
  });
  return {
    overview,
    components,
    dependencies
  };
}
// Replace the existing analyzeCodebase function with analyzeChunkedCodebase
export const analyzeCodebase = analyzeChunkedCodebase;
// Helper to validate a component object
function validateComponent(component: any): boolean {
  if (!component || typeof component !== 'object') {
    logger.error("❌ Invalid component:", component);
    return false;
  }
  const requiredFields = ['type', 'name', 'description'];
  for (const field of requiredFields) {
    if (!component[field]) {
      logger.error(`❌ Component missing required field: ${field}`, component);
      return false;
    }
  }
  return true;
}
// Helper to validate a function object
function validateFunction(func: any): boolean {
  if (!func || typeof func !== 'object') {
    logger.error("❌ Invalid function:", func);
    return false;
  }
  const requiredFields = ['name', 'description', 'parameters', 'returnType'];
  for (const field of requiredFields) {
    if (!(field in func)) {
      logger.error(`❌ Function missing required field: ${field}`, func);
      return false;
    }
  }
  // Validate parameters array
  if (!Array.isArray(func.parameters)) {
    logger.error("❌ Function parameters is not an array:", func.parameters);
    return false;
  }
  return true;
}
// Helper to validate a class object
function validateClass(cls: any): boolean {
  if (!cls || typeof cls !== 'object') {
    logger.error("❌ Invalid class:", cls);
    return false;
  }
  const requiredFields = ['name', 'methods', 'properties'];
  for (const field of requiredFields) {
    if (!(field in cls)) {
      logger.error(`❌ Class missing required field: ${field}`, cls);
      return false;
    }
  }
  // Validate methods array
  if (!Array.isArray(cls.methods)) {
    logger.error("❌ Class methods is not an array:", cls.methods);
    return false;
  }
  // Validate properties array
  if (!Array.isArray(cls.properties)) {
    logger.error("❌ Class properties is not an array:", cls.properties);
    return false;
  }
  return true;
}
// Helper to validate a module object
function validateModule(module: any): boolean {
  if (!module || typeof module !== 'object') {
    logger.error("❌ Invalid module:", module);
    return false;
  }
  const requiredFields = ['name', 'description'];
  for (const field of requiredFields) {
    if (!module[field]) {
      logger.error(`❌ Module missing required field: ${field}`, module);
      return false;
    }
  }
  // Optional arrays should be arrays if present
  if (module.imports && !Array.isArray(module.imports)) {
    logger.error("❌ Module imports is not an array:", module.imports);
    return false;
  }
  if (module.exports && !Array.isArray(module.exports)) {
    logger.error("❌ Module exports is not an array:", module.exports);
    return false;
  }
  if (module.dependencies && !Array.isArray(module.dependencies)) {
    logger.error("❌ Module dependencies is not an array:", module.dependencies);
    return false;
  }
  return true;
}
</file>

<file path="src/mcpHandler.ts">
// MCP protocol handler: registration of commands goes here 
// src/mcpHandler.ts
import { analyzeCode } from './codeAnalyzer';
import { analyzeProject } from './codeAnalyzer/projectAnalyzer';
import { generateDocumentation } from './docGenerator';
import { logger } from './utils/logger';
import Joi from "joi";
// Define schemas for incoming MCP commands using Joi
const analyzeCodeSchema = Joi.object({
  command: Joi.string().valid("analyzeCode").required(),
  code: Joi.string().required(),
  filePath: Joi.string().optional(),
});
const analyzeProjectSchema = Joi.object({
  command: Joi.string().valid("analyzeProject").required(),
  directory: Joi.string().required(),
});
const generateDocsSchema = Joi.object({
  command: Joi.string().valid("generateDocs").required(),
  // Extend this schema if additional properties are required for documentation generation.
});
// Helper function to validate payloads against a given schema
function validatePayload(payload: any, schema: Joi.Schema) {
  const { error } = schema.validate(payload);
  if (error) {
    throw new Error(`Payload validation error: ${error.message}`);
  }
}
export async function handleMCPRequest(request: any): Promise<any> {
  const { command, payload } = request;
  logger.info(`Received command: ${command}`);
  switch (command) {
    case 'analyzeCode':
      validatePayload(payload, analyzeCodeSchema);
      // Payload should include code or path to code
      try {
        const analysisResult = await analyzeCode(payload);
        return { success: true, data: analysisResult };
      } catch (error: unknown) {
        if (error instanceof Error) {
          return { success: false, error: error.message };
        } else {
          return { success: false, error: String(error) };
        }
      }
    case 'analyzeProject':
      validatePayload(payload, analyzeProjectSchema);
      try {
        // Expect payload to have a 'directory' property
        const directory: string = payload.directory;
        const projectAnalysis = await analyzeProject(directory);
        return { success: true, data: projectAnalysis };
      } catch (error: unknown) {
        if (error instanceof Error) {
          return { success: false, error: error.message };
        } else {
          return { success: false, error: String(error) };
        }
      }
    case 'generateDocs':
      validatePayload(payload, generateDocsSchema);
      try {
        const docResult = await generateDocumentation(payload);
        return { success: true, data: docResult };
      } catch (error: unknown) {
        if (error instanceof Error) {
          return { success: false, error: error.message };
        } else {
          return { success: false, error: String(error) };
        }
      }
    default:
      throw new Error(`Unknown command: ${command}`);
  }
}
</file>

<file path="src/types/react-syntax-highlighter.d.ts">
declare module 'react-syntax-highlighter' {
  import * as React from 'react';
  export interface SyntaxHighlighterProps {
    language?: string;
    style?: any;
    children?: React.ReactNode;
    wrapLines?: boolean;
    customStyle?: React.CSSProperties;
  }
  export const Prism: React.ComponentType<SyntaxHighlighterProps>;
  const SyntaxHighlighter: React.ComponentType<SyntaxHighlighterProps>;
  export default SyntaxHighlighter;
}
declare module 'react-syntax-highlighter/dist/esm/styles/prism' {
  export const darcula: any;
}
</file>

<file path="src/types/vfile-modules.d.ts">
declare module '#minproc' {
  export const minproc: any;
}
declare module '#minurl' {
  export const urlToPath: any;
  export const isUrl: any;
}
declare module '#minpath' {
  export const minpath: any;
}
</file>

<file path="src/utils/fileUtils.ts">
import fs from 'fs';
/**
 * Synchronously reads a file with the specified encoding (default: 'utf8') 
 * and returns its contents as a string.
 *
 * @param filePath - The path to the file.
 * @param encoding - The file encoding (default is 'utf8').
 * @returns The file contents as string.
 */
export function readFile(filePath: string, encoding: BufferEncoding = 'utf8'): string {
    return fs.readFileSync(filePath, encoding);
}
/**
 * Synchronously writes data to a file with the specified encoding (default: 'utf8').
 *
 * @param filePath - The path to the file.
 * @param data - The data to write to the file.
 * @param encoding - The file encoding (default is 'utf8').
 */
export function writeFile(filePath: string, data: string, encoding: BufferEncoding = 'utf8'): void {
    fs.writeFileSync(filePath, data, { encoding });
}
/**
 * Checks whether a file exists at the given path.
 *
 * @param filePath - The path to the file.
 * @returns True if the file exists, otherwise false.
 */
export function fileExists(filePath: string): boolean {
    try {
        fs.accessSync(filePath, fs.constants.F_OK);
        return true;
    } catch {
        return false;
    }
}
</file>

<file path="src/utils/logger.ts">
// Basic logging utility 
// src/utils/logger.ts
export const logger = {
    info: (msg: string, ...args: any[]) => {
        console.log(`[INFO] ${msg}`, ...args);
    },
    warn: (msg: string, ...args: any[]) => {
        console.warn(`[WARN] ${msg}`, ...args);
    },
    error: (msg: string, ...args: any[]) => {
        console.error(`[ERROR] ${msg}`, ...args);
    },
};
</file>

<file path="start-app.bat">
@echo off
echo Starting Code Doc Generator...

REM Start the backend server
start cmd /k "npm run start"

REM Start the frontend development server
cd frontend
start cmd /k "npm run dev"

REM Wait for the servers to start
timeout /t 5

REM Open Edge browser
start msedge "http://localhost:5173"

echo App is running!
echo Frontend: http://localhost:5173
echo Backend: http://localhost:3000
</file>

<file path="stop-app.bat">
@echo off
echo Stopping Code Doc Generator...

REM Kill any running Node.js processes
taskkill /F /IM node.exe

echo All servers stopped!
</file>

<file path="tests/codeAnalyzer.test.ts">
import { analyzeCode } from "../src/codeAnalyzer";
describe("Code Analyzer", () => {
  test("analyzes a simple function", async () => {
    const code = "function foo(a, b) {\n  return a + b;\n}\n";
    const result = await analyzeCode({ code, filePath: "dummy.ts" });
    // Validate the analysis result structure
    expect(result).toHaveProperty("functions");
    expect(Array.isArray(result.functions)).toBe(true);
    expect(result.functions.length).toBe(1);
    const fn = result.functions[0];
    expect(fn.name).toBe("foo");
    expect(fn.parameters).toEqual(["a", "b"]);
    expect(typeof fn.startLine).toBe("number");
    expect(typeof fn.endLine).toBe("number");
    expect(fn.filePath).toBe("dummy.ts");
  });
});
</file>

<file path="tests/docGenerator.test.ts">
import { generateDocumentation } from "../src/docGenerator";
beforeEach(() => {
  jest.resetModules();
});
describe("Documentation Generation", () => {
  test("should generate dummy documentation", async () => {
    const payload = {}; // Dummy payload; current implementation doesn't depend on it.
    const result = await generateDocumentation(payload);
    expect(result).toHaveProperty("docs");
    expect(result.docs).toBe("dummy documentation");
  });
});
</file>

<file path="tests/integration.assist.test.ts">
import { assist } from '../src/mcp/integration';
describe('Integration Layer - assist command', () => {
  it('should return a valid assistant response for a valid payload', async () => {
    const payload = {
      code: `function test() { return 42; }`,
      filePath: 'dummyFile.ts'
    };
    const result = await assist(payload);
    expect(result).toHaveProperty('assistantResponse');
    expect(typeof result.assistantResponse).toBe('string');
    expect(result.assistantResponse).toContain('Dummy LangChain response');
  });
});
</file>

<file path="tests/mcpHandler.test.ts">
import { handleMCPRequest } from "../src/mcpHandler";
// Mock the dependent modules
jest.mock("../src/codeAnalyzer", () => ({
  analyzeCode: jest.fn(async (payload) => ({ functions: [], classes: [] })),
}));
jest.mock("../src/codeAnalyzer/projectAnalyzer", () => ({
  analyzeProject: jest.fn(async (directory) => ({ project: "dummy project analysis" })),
}));
jest.mock("../src/docGenerator", () => ({
  generateDocumentation: jest.fn(async (payload) => ({ docs: "dummy documentation" })),
}));
describe("MCP Handler", () => {
  test("analyzeCode valid payload", async () => {
    const request = {
      command: "analyzeCode",
      payload: { command: "analyzeCode", code: "const x = 1;", filePath: "dummy.ts" }
    };
    const response = await handleMCPRequest(request);
    expect(response.success).toBe(true);
    expect(response.data).toEqual({ functions: [], classes: [] });
  });
  test("analyzeCode invalid payload missing code should throw validation error", async () => {
    const request = {
      command: "analyzeCode",
      payload: { command: "analyzeCode", filePath: "dummy.ts" }
    };
    await expect(handleMCPRequest(request)).rejects.toThrow(/Payload validation error/);
  });
  test("analyzeProject valid payload", async () => {
    const request = {
      command: "analyzeProject",
      payload: { command: "analyzeProject", directory: "src" }
    };
    const response = await handleMCPRequest(request);
    expect(response.success).toBe(true);
    expect(response.data).toEqual({ project: "dummy project analysis" });
  });
  test("analyzeProject invalid payload missing directory should throw validation error", async () => {
    const request = {
      command: "analyzeProject",
      payload: { command: "analyzeProject" }
    };
    await expect(handleMCPRequest(request)).rejects.toThrow(/Payload validation error/);
  });
  test("generateDocs valid payload", async () => {
    const request = {
      command: "generateDocs",
      payload: { command: "generateDocs" }
    };
    const response = await handleMCPRequest(request);
    expect(response.success).toBe(true);
    expect(response.data).toEqual({ docs: "dummy documentation" });
  });
  test("unknown command should throw an error", async () => {
    const request = {
      command: "unknownCommand",
      payload: {}
    };
    await expect(handleMCPRequest(request)).rejects.toThrow(/Unknown command/);
  });
});
</file>

<file path="tsconfig.json">
{
    "compilerOptions": {
      "target": "es2018",
      "module": "esnext",
      "moduleResolution": "node",
      "sourceMap": true,
      "outDir": "./dist",
      "rootDir": ".",
      "strict": true,
      "esModuleInterop": true,
      "skipLibCheck": true,
      "baseUrl": "./src",
      "jsx": "react",
      "allowJs": true,
      "checkJs": true,
      "resolveJsonModule": true,
      "forceConsistentCasingInFileNames": true,
      "allowSyntheticDefaultImports": true,
      "maxNodeModuleJsDepth": 1,
      "noImplicitAny": false,
      "noEmitOnError": false,
      "lib": [
        "es2018",
        "dom"
      ],
      "types": [
        "node"
      ],
      "experimentalDecorators": true,
      "emitDecoratorMetadata": true
    },
    "ts-node": {
      "esm": true,
      "experimentalSpecifierResolution": "node"
    },
    "include": ["src/**/*", "tests/**/*"],
    "exclude": ["node_modules", "dist"]
  }
</file>

</files>
